[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistisk dataanalyse med Jamovi",
    "section": "",
    "text": "Forord"
  },
  {
    "objectID": "index.html#hva-trenger-jeg",
    "href": "index.html#hva-trenger-jeg",
    "title": "Statistisk dataanalyse med Jamovi",
    "section": "Hva trenger jeg?",
    "text": "Hva trenger jeg?\nDenne boken bygger videre på Statistisk Dataanalyse, forfattet av Christer Thrane (Thrane 2020). Vi rekommanderer denne som en introduserende tekst samtidig som vi prøver vi å gå litt mer i dybden på noen konsepter her. For å få mer dybde i pensum rekommanderes Innføring i statistikk og dataanalyse for studenter i Idretts- og helsefag.\n\nThrane, Christer. 2020. Statistisk Dataanalyse På 1-2-3. Cappelen Damm.\nFor å følge med i modulene trenger du Jamovi, som du kan installere til din Mac eller PC ved å laste ned programvaren her. Det er også mulig å bruke Jamovi i skyen.\nDet finnes flere alternativer til regnearkprogrammer. Det mest kjente er Microsofts Excel, men du kan også bruke Open Office eller Google sheets. For å forfatte rapporter kan du bruke et ordbehandlingsprogram så som Microsofts Word eller lignende (Google docs, Open Office, Libre Office). Til sist bruker vi en presentasjonsprogramvare (Microsoft PowerPoint) for å redigere figurer."
  },
  {
    "objectID": "01-a-intro.html",
    "href": "01-a-intro.html",
    "title": "Deskriptiv dataanalyse",
    "section": "",
    "text": "I denne modulen introduseres de programmer som vil bli brukt i emnet. Vi vil snakke om hvordan vi kan lagre data og om hvordan vi kan gjennomføre analyser på en ryddig måte. I pensum snakker man om deskriptiv dataanalyse og det typiske i data. Vi prøver å sette dette inn i en kontekst for vitenskapelig dataanalyse. I Jamovi ser vi hvordan vi kan gjennomføre en beskrivende dataanalyse av forskjellige variabeltyper."
  },
  {
    "objectID": "01-deskriptiv-dataanalyse.html#dataanalyse-i-praksis",
    "href": "01-deskriptiv-dataanalyse.html#dataanalyse-i-praksis",
    "title": "1  Datahåndtering og Data i regnearkprogrammer",
    "section": "1.1 Dataanalyse i praksis",
    "text": "1.1 Dataanalyse i praksis\nI dette emnet så foreslår vi at dere bruker excel (eller lignende programmer) for å mate inn og lagre data, og Jamovi for å gjennomføre dataanalyse og lage enkle figurer. Denne kombinasjonen er mer enn nok for å på en god måte klare å ferdigstille et vitenskapelig arbeid hvor du forventes å presentere og tolke data fra et eksperiment eller observasjoner. Vi foreslår dette fordi kombinasjonen er fritt tilgjengelig for deg i et fremtidig arbeidsliv hvor du ikke vil ha tilgang til mer kostbare programvarer, og det finnes muligheter for å gå videre til mer avanserte programvarer (f.eks. R) med utgangspunkt i Jamovi.\nEn dataanalyse i praksis er ikke begrenset til hvilke programvarer du bruker. Det å lære å være systematisk og strukturert kommer å spare deg og dine medarbeidere mye hodebry og tid. En systematisk og organisert dataanalyse er også reproduserbar. Når vi snakker om reproduserbar dataanalyse i denne sammenhengen mener vi at du kan gi din data og analysene til en tredje person som i sin tur kan spore de valg du gjort i dataanalysen.\nReproduserbar dataanalyse er noe som mange snakker om nå da mange mener vi står mitt i en replikasjonskrise. Vitenskapelige funn er ikke alltid mulige å bekrefte i nye studier og det viser seg at andelen funn som ikke kan bekreftes er urovekkende mange! Forskjellige problemer og løsninger er foreslått for å lage bedre vitenskap og en stor del av dette går ut på å gjøre vitenskapelig analysearbeid mer transparent.\nEn reproduserbar dataanalyse inneholder all informasjon som kreves for å gjenskape analyseresultatene. En transparent dataanalyse inneholder også beskrivninger av hvorfor og hvordan man valgt å lage analysen på en gitt måte. For å gjøre dette mulig så kreves ytterligere struktur til et prosjekt.\nEt enkelt oppsett kan være å tenke på dataanalysen som en isolert mappe på din PC. I mappen finner man alt som kreves for å gjenskape eller forstå din analyse. Her finnes:\n\nRådata: Data som er urørt etter det at man matet inn eller innhentet den i forskjellige programmer osv.\nDelvis bearbeidet data: Data som er organisert for data analyse\nAnalysefiler: Filer som er kan lese til eks. Jamovi og inneholder analyser av din data\nRapporter og figurer: Disse er sluttprodukter av deres arbeid, disse kan settes sammen til eks. en bachelor-oppgave.\n\nFor å beskrive alle disse delene bør du også ha en fil som beskriver de forskjellige filene i analysen og den overordnede hensikten med hele prosjektet. Denne informasjonen kan beskrives i en fil som vi navngir README. En README-fil bør skrives i et format som ikke krever spesielle programvarer for å lese (eks. .txt). I presentasjonen finner dere et eksempel på en README-fil for et prosjekt in progress. README-filen er et levende dokument og bør gjenspeile forandringer i prosjektet, en overskrift med oppdateringer kan hjelpe å holde styr på fremgangen i prosjektet.\nTil sist bør vi vurdere hvordan vi navngir prosjekter. Da disse bør være isolerte (self-contained), og inneholde all informasjon så bør også mappen/prosjektet ha et navn som beskriver innehold. Unngå eks. Prosjekt1, Prosjekt2 osv. Prøv istedenfor å lage beskrivende navn, noe som gir en hint om hva prosjektet ønsker å gjøre eller besvare."
  },
  {
    "objectID": "01-deskriptiv-dataanalyse.html#beskrive-data",
    "href": "01-deskriptiv-dataanalyse.html#beskrive-data",
    "title": "1  Datahåndtering og Data i regnearkprogrammer",
    "section": "1.2 Beskrive data",
    "text": "1.2 Beskrive data\nVi kan begynne med å sette beskrivende statistikk i konteksten av målet med mye av de statistiske analysene i vitenskapelig arbeid. Her ønsker vi ofte å si noe om en “populasjon”, dette gjør vi basert på et “utvalg” som blir brukt for å skape noen form av “modell” av populasjonen. Målet med statistikken er å si noe om noe som vi ikke observerer basert på noe som vi observerer! Vi vill komme tilbake til detaljene i dette senere i denne boken.\nMålet med den beskrivende statistikken er som Thrane sier, “å forenkle en stor uoverskuelig mengde informasjon”, som kan være vår data. Dataene består av variabler, innen forskningens verden beskriver en variabel et fenomen vi er interessert i å studere. En variabel bygges gjennom operasjonalisering, et teoretisk konsept kobles til en målbar enhet som i sin tur blir til en variabel i våres datasett.\nVi beskriver de data og dermed variablene vi har på en måte som gir økt forståelse for dess karakteristikk. En slik karakteristikk er dataenes sentraltendens (Figur 1.1). Et mål på sentraltendens er gjennomsnittet som er den verdi som balanserer verdiene i dataen. Dette betyr at like mye vekt finnes på begge sider av gjennomsnittet i formen av tallverdier. Median er et annet mål på sentraltendens, her balanseres isteden antall verdier. Vi rangerer verdiene i dataen fra store til små og setter median til den verdi som er midten av datasettet. Modus er et annet mål på sentraltendens, her finner vi det tall som finnes flest ganger i datasettet.\n\n\n\n\n\nFigur 1.1. Tre forskjellige mål på sentraltendens.\n\n\n\n\nThrane introduserer noen matematisk notasjon i en fotnote. Jeg ønsker å formidle at dere ikke trenger å være redde for disse formlene. Statistikken er full av matematisk notasjon og med en grunnleggende forståelse kan vi lese mye av den. En noe mer komplisert formel for gjennomsnittet kan gis som\n\\[\\bar{x} = \\frac{\\sum_{i=1}^{n}{x_i}}{n}\\]\nhvor \\(\\bar x\\) står får gjennomsnittet av variabelen \\(x\\). Summen av \\(n\\) antall observasjoner over et indeks \\(i\\) som starter med tallet 1 for variabelen \\(x\\) skrives som \\(\\sum_{i=1}^{n}{x_i}\\). Summen delt på antall observasjoner \\(n\\) gir oss gjennomsnittet.\nForskjellen mellom gjennomsnitt, median og modus sier noe om hvilken informasjon vi trekker ut fra dataene. Gjennomsnittet måler tallverdier, medianen måler rangering og modus måler forekomst av spesifikke tallverdier. Mest informasjon finner vi i data som kan beskrives på en skala hvor avstand mellom verdier er lik over hele skalaen og det finnes et absolutt nullpunkt. Denne typen av data kan beskrives som forholdstallsnivå (ratio scale). Når dataene savner et absolutt nullpunkt sier vi at vi har data på intervallnivå. Informasjonen som vi har på forholdstallsnivå og intervallnivå kan reduseres til kategorier hvor informasjon om avstand mellom tallverdier forsvinner. For eksempel kan vi klassifisere gjennomsnittlig dagtemperatur til varm (&gt; 18°C), lunken (&lt; 18°C) og kald (&lt; 0°C). Rangering er fortsatt mulig, varm temperatur rangeres over kald, men avstand mellom kategoriene gir ikke mening. Vi har nå skapt en variabel på ordinalnivå hvor verdier er ordnet, men savner sammenligningsbare avstander mellom verdiene. Til sist kan vi snakke om et nominalnivå, her finner vi kategorier som savner rangering (mann/kvinne, kjønn osv.). Denne oppdelingen er en grunn til klassifisering av forskjellige datatyper. Numerisk data kan kategoriseres som intervalldata og forholdstall, kategorisk data kan beskrives som mulig eller ikke mulig å rangere (ordinal og nominalnivå). Datatyper bestemmer hvilke analyser vi kan bruke for å forstå dataene.\nKategorier er vanskelige å gi et gjennomsnitt da tallverdien i seg ikke er av betydelse, isteden finnes informasjonen i rangering eller forekomst. Andeler kan hjelpe oss å bedre redusere kategorisk data til overskuelig informasjon. Data som finnes i kategorier kan beskrives ved hjelp av andeler av en total. Dette er den mulighet vi har for å sammenstille forekomst av kategorier.\n\n1.2.1 Variasjon\nEn variabels variasjon kan også beskrives, med begrensinger i hvilken type data vi har. I numerisk data på kvote eller intervallskala kan vi beskrive gjennomsnittlig avvik fra gjennomsnittet. Denne kvantiteten er utrolig viktig innen statistikken da den blir brukt for å kvantifisere bland annet usikkerhet. For å beregne avstanden fra gjennomsnittet bruker vi avstanden i kvadrat\n\\[(x_i-\\bar{x})^2\\]\nhvor \\(\\bar{x}\\) er gjennomsnittet og \\(x_i\\) er en enkelt observasjon. Et gjennomsnitt av summen av alle avvik (\\(s^2\\)) fra gjennomsnitt i kvadrat kan skrives som\n\\[s^2 = \\frac{\\sum{(x_i-\\bar{x})^2}}{n-1}\\]\nHer bruker vi \\(n-1\\) for å få et tall på variasjonen i utvalget som ikke skiller seg betydelig fra populasjonen1. Det vi har beregnet her er variansen, for å sette variansen på den samme skalaen som gjennomsnittet bruker vi1 Se her for en delvis forklaring\n\\[s = \\sqrt{\\frac{\\sum{(x_i-\\bar{x})^2}}{n-1}}\\]\nDette tall (\\(s\\)) kalles standardavvik, dette er det gjennomsnittlige avviket fra gjennomsnittet på den samme skalaen som gjennomsnittet. Standardavviket er også et tall som vi vil høre mye om når vi oppdager statistikken videre. Ved hjelp av gjennomsnittet og standardavviket har vi tilstrekkelig informasjon for å lage mer eller mindre kompliserte modeller av verden omkring oss.\nProsentiler (data oppdelt i 100 deler) eller kvartiler (data oppdelt i 4 deler) er tallverdier som tilsvarer forskjellige andeler av dataen. Medianen er midten av en variabel, dette er også den 50:e prosentil, eller den andre kvartil. Interkvartilavstanden er avstanden mellom den første og den tredje kvartil, innen dette intervallet finner vi 50% av alle tall i en variabel.\nNår vi beveger oss til datatyper hvor avstand mellom tall på skalaen ikke har lik mening (for eksempel mellom kategorier) trenger vi andre mål på variasjon. Her kan vi istedenfor bruke minimum og maksimum eller variasjonsvidde (gitt at kategorier er rangerte).\nForskjellige statistikker (for eksempel gjennomsnitt, standardavvik osv.) kan gi mye informasjon og er noe vi trenger for å forstå vår data. Noen ganger er det bedre med visuell informasjon. Her kan vi oppdage mønster og karakteristikker som ikke er så lette å se i spesifikke tall."
  },
  {
    "objectID": "01-deskriptiv-dataanalyse.html#introduksjon-til-jamovi",
    "href": "01-deskriptiv-dataanalyse.html#introduksjon-til-jamovi",
    "title": "1  Datahåndtering og Data i regnearkprogrammer",
    "section": "1.3 Introduksjon til Jamovi",
    "text": "1.3 Introduksjon til Jamovi\nJamovi er et statistikkprogram som muliggjør enklere til svært avanserte statistiske analyser. Jamovi inneholder trolig alt du trenger for å levere en bachelor-oppgave. Jamovi er gratis, skrevet med åpen kildekode og brukere av programmet kan lage egne moduler som gir programmet flere analysemuligheter. Jamovi er skrevet ved hjelp av programmeringsspråket R, om du ønsker å lage mer avanserte analyser eller figurer så har du mulighet å ta analysene du allerede gjort i Jamovi til R.\nDet finnes flere andre alternativer til Jamovi som gir nesten de samme fordelene (åpen kildekode, gratis, modulbasert) som JASP, PSPP og Deducer. Valget mellom disse kan gjøres basert på tilgjengelige læringsressurser. Jamovi stiller her sterkt:\n\n\n\nRessurs\nlenke\n\n\n\n\nIntroduksjonskurs i Jamovi med videoinstruksjoner for flere statistiske analyser\ndatalab.cc/jamovi\n\n\nGratis e-bok som dekker statistiske metoder og bruk av Jamovi\nLearnings statistics with Jamovi\n\n\nJamovi user guide, dekker alle de grunnleggende funksjonene\nJamovi user guide\n\n\nJamovieguiden, på Norsk, guider med bilder på prosedyrer i Jamovi\nJamovieguiden\n\n\nSe også en oppdatert liste med ressurser her\nCommunity resources\n\n\n\nI tillegg finnes det i disse notatene flere beskrivelser av hvordan man gjennomfører analyser i Jamovi.\nFør du går videre, last ned og installer Jamovi på din PC/Mac."
  },
  {
    "objectID": "01-jamovi.html#deskriptiv-dataanalyse-i-jamovi",
    "href": "01-jamovi.html#deskriptiv-dataanalyse-i-jamovi",
    "title": "2  Deskriptiv dataanalyse i Jamovi",
    "section": "2.1 Deskriptiv dataanalyse i Jamovi",
    "text": "2.1 Deskriptiv dataanalyse i Jamovi\nI eksemplene under vil vi bruke et data sett fra Thrane (2020) som du finner her. Nå er det lurt å bruke det du lært så langt når du lagrer filene på din datamaskin. Sett opp en mappe som omhandler denne første modulen i emnet, navngi den f.eks. deskriptiv-dataanalyse og lagre filen i en undermappe som heter data. I denne mappen kan du senere lagre analysefilen fra dit statistikkprogram, eventuelle figurer og notater.\n\nThrane, Christer. 2020. Statistisk Dataanalyse På 1-2-3. Cappelen Damm.\nFor å importere data i Jamovi som er lagret i en csv-fil bruker vi Open i hovedmenyen. Last ned og lagre datasettet som beskrevet over og åpne det direkte i Jamovi. Bruk Browse for å finne frem til filen du ønsker å åpne. Hvis du allerede har brukt filen tidligere i Jamovi finner du den under recent (se bilde under). Du vil nå se datasettet representert i Jamovi i form av kolonner og rader. Legg merke til at data er strukturert som variabler i kolonner og observasjoner i rader. Navn på variabler inneholder ikke noen spesialtegn eller mellomrom, noe som kan være vanskelig for Jamovi å bearbeide. Datasettet som Thrane gir oss, er velstrukturert for videre behandling i et statistikkprogram!\nDatasettet kan beskrives ytterligere i Jamovi under fanen Variables. Hvert variable er her listet med navn og du kan legge til en beskrivelse (Description). Her finnes også mulighet å editere, beregne, transformere, legge til og ta vekk variabler. Det å editere variabler innebærer at vi forandre variabeltypen\nI denne første modulen er vi opptatt av deskriptiv eller beskrivende datanalyse. Funksjoner for dette finner vi under analyses"
  },
  {
    "objectID": "02-a-intro.html",
    "href": "02-a-intro.html",
    "title": "Statistisk samvariasjon",
    "section": "",
    "text": "I denne modulen introduserer vi noen teknikker for å måle statistisk samvariasjon med fokus på regresjonsanalyse. Modulen introduserer teknikker og inneholder demonstrasjoner i Jamovi. Til modulen hører en quiz (arbeidskrav) hvor det kreves alle rette. Du har ubegrenset med forsøk på quizen men vi oppfordrer deg til å bruke den for å identifisere dine svake sider. Er det noe du ikke skjønner, bruk mer tid på å forberede deg for de spørsmålene ved gjentatte forsøk."
  },
  {
    "objectID": "02-statistisk-samvariasjon.html#regresjon",
    "href": "02-statistisk-samvariasjon.html#regresjon",
    "title": "3  Statistisk samvariasjon i dataanalyse",
    "section": "3.1 Regresjon",
    "text": "3.1 Regresjon\nRegresjonsanalyse er en familie av teknikker for å måle samvariasjon mellom to eller flere variabler. I den enkleste formen kan vi faktisk bruke en variabel, når vi legger til en ytterligere variabel lager vi en modell som gir oss en matematisk formel for hvordan en variabel påvirker en annen. I denne enkle formen snakker vi om at en uavhengig variabel påvirker en avhengig variabel. Disse kan plottes i en to-dimensjonal figur. På x-aksel setter vi den uavhengige variabelen og på y-aksel setter vi den avhengige variabelen.\nI dette “systemet”, og med benevningene avhengig og uavhengig variabel sier vi noe om hvordan vi forestiller oss at variablene varierer sammen. Vi sier noe om at den uavhengige variabelen påvirker den avhengige. Modellen kan brukes for å lage prediksjoner om hvilken verdi den avhengige variabelen tar hvis hvis vi bestemmer at den uavhengige variabelen skal ha en gitt verdi.\nTil tross for at vi vet at flere variabler i mange fall påvirker en avhengig variabel kan vi bruke regresjonsmodellen for å estimere sammenhengen mellom et begrenset antall variabler. I tabellen under finnes data på kroppshøyde og vekt hos en gruppe (mer eller mindre kjente) individer. En enkel og forholdsvis kort tabell som denne kan gi en overblikk over dataene, men en matematisk modell kan forenkle sammenhengen mellom høyde og vekt ytterligere. Vi velger å sette høyde som uavhengig variabel og vekt som avhengig variabel. Alt annet like så kan vi tenke oss at hvis kroppshøyde øker så øker vekt, men øker vekt så trenger ikke høyde øke. Det finnes en logisk retning på sammenhengen mellom variablene.\n\n\n\nNavn\nHøyde (cm)\nVekt (kg)\n\n\n\n\nBart Simpson\n121.92\n38.56\n\n\nLisa Simpson\n160.02\n53.98\n\n\nHomer Simpson\n180.34\n108.4\n\n\nMarge Simpson\n172.72\n63.05\n\n\nMaggie Simpson\n73.66\n9.07\n\n\nMilhouse Van Houten\n124.46\n29.94\n\n\nNed Flander\n175.26\n68.95\n\n\n\nNår vi setter inn disse tallene i en figur og gir hver observasjon en symbol så kan vi allerede se en tendens i dataene. Individer som er høyere er også tyngre. En matematisk modell for denne sammenhengen kan brukes for å beskrive gjennomsnittet ved en gitt høyde, men hvor plasserer vi dette gjennomsnittet?\nEn regresjonslinje kan beskrives med formelen \\[y=m + k\\times x\\] Vi kjenner denne formelen fra matematikken og vi kan lese den som at \\(y\\) er lik skjæringspunktet (\\(m\\)) pluss \\(k\\) (stigningstall) enheter per hver enhets endring i \\(x\\). I statistikken bruker man ofte andre tegn for å beskrive skjæringspunkt og stigningstall. Den samme ekvasjonen kan se ut slik i statistikkboken \\[y=\\beta_0 + \\beta_1 \\times x\\] Hvor \\(\\beta_0\\) og \\(\\beta_1\\) er skjæringspunkt og stigningstall. Disse er koeffisienter som estimeres fra dataene. Når vi setter \\(x=0\\) faller \\(\\beta_1\\) ut fra ekvasjonen og vi står igjen med \\(y=\\beta_0\\), skjæringspunktet. For hver enhet forandring i \\(x\\) forandres \\(y\\) med \\(\\beta_1\\).\nFor å estimere \\(\\beta_0\\) og \\(\\beta_1\\) ønsker vi å plassere regresjonslinjen (modellen for gjennomsnittet) på gjennomsnittet for hver \\(x\\). I figur A ser vi en modell som beskriver to punker meget godt, Figur B og C er ikke lette å skille, disse beskriver punktene med cirka like store feil. Hvilken modell er den korrekte?\nEn regresjonsmodell estimeres ved å minimere avstanden fra hver observasjon til dess respektive predikerte verdi. Teknisk sett så minimerer vi summen av avstanden i kvadrat. Her kan vi illustrerer dette gjennom å plotte alle modellene med feilverdier til hver observasjon. Når ve legger disse sammen blir det tydelig at den blå modellen ikke er særlig god. Den minimerer avstand til to observasjoner på bekostning av stor feil i de andre observasjonene.\nEt dataprogram gjennomfører beregninger for oss og gir oss modellen hvor feilene er minimerte. Resultatene fra en tilpassing av en regresjonsmodell kan leses i en tabell hvor estimatene av skjæringspunkt og stigningstall vises. I eksemplet med kroppshøyde og vekt ser vi at stigningstallet er 0.7 kg. For hver cm økning i kroppshøyde øker vekt med 0.7 kg. Skjæringspunktet sier at vekten er -51 kg hvis kroppshøyde er 0. Dette er ikke en korrekt representasjon av verden så som vi kjenner den. Dette sier mer om regresjonsteknikken enn om forholdet mellom kroppshøyde og vekt.\nEn regresjonsmodell fungerer best hvor vi faktisk har data. En enkel regresjonsmodell begrenses også til rette linjer. Dette gjør at resultatene fra en slik analyse bør behandles med skepsis når vi kan gjøre antagelser om et ikke rett sammenheng og når modellen brukes for å predikere utenfor området hvor modellen ble lagd."
  },
  {
    "objectID": "02-statistisk-samvariasjon.html#regresjon-med-en-nominal-eller-ordinal-uavhengig-variabel",
    "href": "02-statistisk-samvariasjon.html#regresjon-med-en-nominal-eller-ordinal-uavhengig-variabel",
    "title": "3  Statistisk samvariasjon i dataanalyse",
    "section": "3.2 Regresjon med en nominal eller ordinal uavhengig variabel",
    "text": "3.2 Regresjon med en nominal eller ordinal uavhengig variabel\nVi kan enkelt omformulere modellen gjennom å bruke en nominal eller ordinal variabel som uavhengig variabel. La oss si at vi ønsker å estimere sammenheng mellom alderskategoriene barn/voksen og vekt. I tabellen under har vi identifisert voksne og barn, ett statistikkprogram vil omformulere denne informasjonen til en dummyvariabel. En dummyvariabel kan en enkel form ta to verdier (0 og 1), og her kan vi forstå den som voksen ja = 1/nei = 0).\n\n\n\nNavn\nHøyde (cm)\nVekt (kg)\nAlderskategori\nAlderskategori (dummy)\n\n\n\n\nBart Simpson\n121.92\n38.56\nBarn\n0\n\n\nLisa Simpson\n160.02\n53.98\nBarn\n0\n\n\nHomer Simpson\n180.34\n108.4\nVoksen\n1\n\n\nMarge Simpson\n172.72\n63.05\nVoksen\n1\n\n\nMaggie Simpson\n73.66\n9.07\nBarn\n0\n\n\nMilhouse Van Houten\n124.46\n29.94\nBarn\n0\n\n\nNed Flander\n175.26\n68.95\nVoksen\n1\n\n\n\nDa tilpassingen av modellen vil bli gjort gjennom at regresjonslinjen beskriver gjennomsnittet for hvert tall på \\(x\\) vil denne modellen beskrive skjæringspunktet som er gjennomsnittet når \\(x=0\\), altså for alderskategorien barn. Stigningstallet vil beskrive hvor mye \\(y\\) (vekt) øker når vi går fra 0 til 1 på \\(x\\)-variabelen.\nHer ser vi også en viktig poeng med sammenligninger i regresjonsanalyser. Når vi observerer data kan vi bruke regresjonsmodellen til å lage sammenligninger. Vi kan ved hjelp av \\(x\\)-variabelen sammenligne to kategorier, eller gjennomsnitt på \\(y\\) ved to forskjellige verdier på \\(x\\). Teknisk sett så kan vi ikke si “hvis vi øker \\(x\\) med 1 for et individ så vil dettet individet få \\(\\beta_1\\) enheter større \\(y\\)” da vi ikke har mulighet på gjennomføre en intervensjon på dette individet. Noen uavhengige variabler er ikke heller enkle å forandre (alder, kjønn, hårfarge osv.)."
  },
  {
    "objectID": "02-statistisk-samvariasjon.html#flere-uavhengige-variabler",
    "href": "02-statistisk-samvariasjon.html#flere-uavhengige-variabler",
    "title": "3  Statistisk samvariasjon i dataanalyse",
    "section": "3.3 Flere uavhengige variabler",
    "text": "3.3 Flere uavhengige variabler\nEn regresjonsmodell kan ha flere uavhengige variabler som sammen forklarer en avhengig variabel. I en ligning kan dette se ut som\n\\[y=\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n\\] Nå vi setter noen av de uavhengige variablene til noe annet enn 0 så gir vi koeffisientene betydelse for resultatet (\\(y\\)). I teorien kan vi ha veldig mange uavhengige variabler, men i praksis er dette noe som er vanskelig å motivere av statistisk og vitenskapelig hensyn (noe vi ikke går dypere inn på i denne kurs).\nI datasettet student_trening_1_2_3.csv finner vi variablene alder, kjønn og treningstimer. Vi ønsker å finne sammenhengen mellom variablene kjønn og alder (uavhengige variabler) og treningstimer (avhengig variabel). Modellen kan skrives som\n\\[\\text{treningstimer} = \\beta_0 + \\beta_1\\times\\text{kjønn} + \\beta_2\\times\\text{alder}\\] Når vi estimerer modellen får vi tall på \\(\\beta_0\\), \\(\\beta_1\\) og \\(\\beta_2\\). Disse estimatene forteller oss om den gjennomsnittlige forskjellen mellom kjønn i treningstimer ved en gitt alder (\\(\\beta_1\\)) og forskjellen i treningstimer når vi sammenligner for eksempel noen med alder 20 og noen med alder 21 (\\(\\beta_2\\)) hos menn og kvinner. Vi kan si dette da dataprogrammet estimerer koeffisientene ved å minimere feilene (avstand fra predikerte til observerte verdier), akkurat som i fallet med en avhengig variabel, men med forskjellen at vi her minimerer feilene i to dimensjoner (kjønn og alder). Noen sier at vi “kontrollerer” for kjønn når vi ser på effekten av alder, eller at vi “kontrollerer” for alder når vi ser på effekten av kjønn på treningstimer. Vi kan tenke oss at modellen gir et estimat av forskjellen mellom kjønn gitt at variabelen alder er likt fordelt mellom menn og kvinner.\nEstimatet fra modellen over sier at menn trener 1.51 timer mer enn kvinner. Om vi sammenligner gjennomsnittlig treningstid mellom to etterpåfølgende år så finner vi at treningstiden synker med 0.07 timer per år. Hvis vi gjør denne analyses med regresjonsmodeller som ikke inneholde begge variablene så ser vi at effekten av kjønn synker til 1.45 timer (differens mellom menn og kvinner) og effekten av alder synker til -0.05. Den justering som gjøres er en effekt av at alder ikke er fordelt likt mellom menn og kvinner. Når vi sammenligner menn og kvinner uten å “kontrollere” for alder sammenligner vi to grupper med forskjellige aldersprofiler. Da alder også viser sammenheng med treningstimer løper vi risken å til dels ikke lage en rettvis sammenligning.\n\n3.3.1 Antagelser og diagnostikk\nHver regresjonsmodell1 resulterer i et feilledd. Vi har snakket over om at den linje som best beskriver dataene er den linje som minimerer feilen fra modell til data. Feilene i modellen, også kalt residualene, kan brukes for å bedre forstå om modellen er en tilstrekkelig god representasjon av dataene (og verden). For at en modell skal anses representere de verden den prøver å beskrive så er det knuttet noen antagelser til modellen. Vi antar at feilleddet er symetrisk fordelt og ligner en normalfordeling2. Vi antar også at variasjonen eller spredningen (fra modellen, til dataene) er lik over hele datamaterialet, dette kalles homoskedastisitet (lik spredning). Til sist så tenker vi oss at alle observasjoner, og dermed også feilleddet er uavhengige fra hverandre. Det siste betyr at vi ikke på en enkel måte kan bruke flere datapunkter fra de samme individene i en ordinær regresjonsmodell da datapunktene er beslektet.1 Her snakker vi om regresjonsmodeller med en kontinuerlig avhengig variabel.2 Les mer om normalfordeling her: https://no.wikipedia.org/wiki/Normalfordeling\nKonsekvensen av å ikke oppfylle antagelsene over har konsekvenser for hvor godt vi kan bruke modellen for å si noe om populasjonen som dataene kommer i fra. Dette temaet kommer vi tilbake til senere i kurset.\nNår modellen er en rett linje følger ytterligere antagelser om forholdet mellom data og modell. Vi antar at vi faktisk beskriver et lineært forhold mellom avhengig og uavhengig variabel. Hvis vi har indikasjoner på at forholdet ikke er lineært så er ikke heller den rette linjen en god modell. Til dels kan vi bruke feilleddet for å se dette. Men vi kan også prøve å se etter mønster i dataene i forkant av at vi skaper modellen. En regresjonsmodell kan påvirkes i stor grad av et enkelt datapunkt. En observasjon kan “trekke” regresjonslinjen i en retning som ikke overensstemmer med resten av dataene. Dessverre er det ikke lett å finne ut om datapunktet er en del av representasjon av populasjonen som observasjonene kommer fra eller om det er målefeil eller lignende. Her kan det være lurt å lage to modeller for å se hvor godt en konklusjon står i lyset av en influerende datapunkt."
  },
  {
    "objectID": "02-statistisk-samvariasjon.html#regresjon-i-jamovi",
    "href": "02-statistisk-samvariasjon.html#regresjon-i-jamovi",
    "title": "3  Statistisk samvariasjon i dataanalyse",
    "section": "3.4 Regresjon i Jamovi",
    "text": "3.4 Regresjon i Jamovi\nVi starter med datasettet egg_kolesterol_1_2_3.csv. For å lage en regresjonsmodell i Jamovi går vi inn i modulen Regression og velger Linear regression. Her velger vi dependent variable (avhengig variabel). Slik vi formulerer hypotesen om forholdet mellom egg og kolesterol tror vi egg påvirker kolesterolet. Kolesterol er derfor vår avhengige variabel.\nJamovi gjør et skille mellom covariates og factors. Disse er begge uavhengige variabler men covariates krever kontinuerlig data og factors håndterer data som ordinal/nominal data. Vi setter inn egg som en kontinuerlig covariate.\nNår variablene er lagt inn får vi to tabeller i resultatfeltet. Model fit Measures sier noe om styrken i sammenhengen mellom variablene. R tilsvarer korrelasjonskoeffisienten (se under) når modellen inneholder en uavhengig variabel.\nI tabellen Model Coefficients - kolesterol se vi skjæringspunkt (Intercept) og stigningstall egg under Predictor. Under Estimate ser vi de estimat som modellen lager. 3.94 er gjennomsnittlig kolesterolnivå når eggkonsumpsjon er 0, for hvert egg så stiger kolesterolet med 0.86 enheter. For hvert estimat finner vi et standardfeil (SE), t-verdi (t) og p-verdi. Disse bruker vi får å trekke konklusjoner om populasjonen dataene kommer ifra. Tallene er forskjellige mål på usikkerhet, noe vi skal snakke mer om senere.\nI modulmenyen finner vi Assumption checks. Her finnes flere alternativer for å sjekke antagelser. Jeg foreslår at man først fokuserer på Q-Q plot of residuals. Denne figuren viser hvor godt residualene følger en normalfordeling. Hvis punktene er nærme den rette linjen så følger vi normalfordelingen og vi kan sies ha støtte for antagelsen om at residualene er normalfordelte (symetriske). Residual plots gir oss en indikasjon på hvor likt spredning feilleddet har over datamaterialet. I figuren som viser Fitted vs. Residuals ønsker vi å se at vi har likt feil over hele dataene. Muligens ser vi en tendens til mer spredning i kolesterol ved større predikerte verdier.\nBegge disse to grafiske metodene bør studeres ved regresjonsanalyse, men med små datasett kreves det store brudd mot antagelser for at vi skal finne dem. Figurene er vanskelige å tolke med lite data.\nUnder modulmenyen Estimated Marginal Means finner vi en mulighet for å lage en grafisk representasjon av modellen når vi legger inn prediktoren under Marginal Means. Velger vi også Marginal means table får vi det estimerte kolesterolnivået ved gjennomsnittet i variabelen egg pluss og minus et standardavvik.\n\n3.4.1 Multippel regresjon med Jamovi\nI datasettet fotball_1_2_3.csv kan vi stille spørsmål til hvordan årsinntekt påvirkes av spillerbørs karakter gitt at ser denne sammenhengen er betinget opprinnelse og posisjon. Med betinget for mener vi at vi kontrollerer for disse effektene når vi undersøker sammenhengen mellom variablene som interesserer oss. Modellen ser ut slik:\n\\[\\text{arsinntekt} = \\beta_0 + \\beta_1\\times\\text{spillerbors} + \\beta_2\\times\\text{opprinnelse} +\\beta_3\\times\\text{posisjon}\\] Variabelen opprinnelse har to nivåer, Norsk og Utenlandsk. I modellen vil denne variabelen bli lagt til som en dummyvariabel hvor Norsk er referansenivået. Den estimerte koeffisienten \\(\\beta_2\\) vil “aktiveres” når dummyvariabelen settes til 1, det vil si, når vi observerer en Utenlands spiller. Koeffisienten gir oss altså gjennomsnittlig forskjell i årsinntekt mellom Norsk og Utenlandsk opprinnelse.\nVariablene posisjon har fire nivåer, angrep (referansenivå), forsvar, keeper og midtbane. I regresjonsmodellen vil disse bli representert med tre dummyvariabler. Vi vil ikke se disse annet en som sammenligninger med referansenivået (angrep). I tabellen under ser du hvor dummyvariablene konstrueres for observasjoner i de forskjellige posisjonene\n\n\n\nPosisjon\nDummy forsvar\nDummy keeper\nDummy midtbane\n\n\n\n\nAngrep\n0\n0\n0\n\n\nForsvar\n1\n0\n0\n\n\nKeeper\n0\n1\n0\n\n\nMidtbane\n0\n0\n1\n\n\n\nNår modellen beregner gjennomsnitt for angrep settes alle dummyvariablene til 0. Når modellen representerer en gjennomsnittlig forsvarsspiller settes dummyvariablene forsvar til 1 og koeffisienten for forsvar “aktiveres”. Koeffisientene for de forskjellige posisjonene sammenlignes med referansenivået angrep.\nVi kontrollerer først datatyper i datafanen, spillerbørs kan endres til en kontinuerlig variabel, opprinnelse er en nominal variabel, men Norsk er referansenivå, indikert ved at vi finner denne i toppen av levels. Likeså er angrep referansenivået i den nominale variabelen posisjon. Årsinntekt er en kontinuerlig variabel, vi beholder den slik for nå.\nI bakgrunnen har vi altså følgende modell\n\\[\\text{arsinntekt} = \\beta_0 + \\beta_1 x_\\text{spillerbors} + \\beta_2 x_\\text{Utenlandsk} +\\beta_3 x_\\text{forsvar} + \\beta_4 x_\\text{keeper} +\\beta_5 x_\\text{Midtbane}\\]\nVi prøver oss på en modell, årsinntekt i avhengig variabel (Dependent variable), spillerbørs i Covariates, posisjon og opprinnelse i Factors. Før vi ser på estimatene ser vi på antagelser under Assumption checks. Den resulterende figuren Q-Q Plot ser ikke lovende ut, den indikerer at residualene ikke følger en normalfordeling. Residuals vs. Fitted indikerer at spredningen i feilleddet er større ved større predikerte tall. Modellen har mer feil når de predikerte inntektene er større.\nDet finnes noen grep man kan ta for å lage en modell som til større grad følger de antagelser vi setter opp. Et vanlig grep er å log-transformere den avhengige variabelen. Dette kan gi oss en data som passer bedre i en ordinær lineær regresjonsmodell. Log-transformering innebærer at vi tar logaritmen av den originale variabelen, dette betyr at istedenfor å se på dataene på lineær skala ser på dem på en multiplikativ skala. Resultatene fra modellen vil også fortelle oss om relativa forandringer istedenfor absolutt forandring. Hvorfor?\nVi kan starte med å se på noen regler for logaritmer. Først den multiplikasjon på naturlig skala gir addisjon på log-skala:\n\\[log(xy)= log(x) + log(y)\\] Subtraksjon på log-skala gir oss ratio på naturlig skala\n\\[log(x/y) = log(x) - log(y)\\] Et tall som vi finner på log-skala kan transformeres tilbake til naturlig skala ved å bruke eksponentialfunksjonen \\(e\\) (vanligvis bruker vi naturlige logaritmer).\n\\[e^{log(y)} = y\\] I en enkel regresjonsmodell finner vi fra et stigningstall forandring i \\(y\\) basert på en enhets forandring i \\(x\\). På naturlig skala er forandring absolutt og en differens \\(y_{x=1} - y_{x=0}\\) (differensen mellom \\(y\\) når \\(x\\) er lik 0 og \\(y\\) når \\(x\\) er 1). Når vi har den avhengige variabelen på log-skala gir modellen oss fortsatt differensen, men vid transformering til naturlig skala har vi et ratio\n\\[log(y_{x=1}) - log(y_{x=0}) = log(\\frac{y_{x=1}}{y_{x=0}})\\] Når et stigningstall i en modell med en log-transformerte avhengig variabel er for eksempel 0.2 enheter gir dette at vi ser en økning med 22% for hvert økning i den uavhengige variabelen:\n\\[(e^{0.2} -1) \\times 100 = 22\\%\\] Vi kan lese dette resultatet som at hvor enn vi starter i vår avhengige variabel så estimerer modellen en 22% økning for hvert enhets økning i uavhengig variabel. Dette er en relativ økning som i absolutte tall er forskjellig hvis vi starter med 10 (\\(10\\times 0.22=2.2\\)) eller 1000 (\\(1000 \\times 0.22 = 220\\)).\nFor å transformere en variabel i Jamovi legger vi til en transformering. Gå til datafanen, marker årsinntekt og trykk på transform. Under using transform skaper vi en ny transformering (Create new transform), og legger inn =LN($source) i formelfeltet. I formelfeltet står $source for variabelen som skal brukes i transformeringen, LN er funksjonen for den naturlige logaritmen. Vi kan navngi den nye transformering til “LOG”. En ny variabel skapes med en bestemt Source variable og vår definerte transform (using transform).\nVi byter ut den tidligere variabelen med vår nye log-transformerte variabel og ser på Assumption checks. Dette ser bedre ut, residualene er nærmere normalfordelt og spredningen i residualfiguren spreder likt over hele datamaterialet. Vi kan nå tolke resultatene.\nFor hvert poeng økning i spillerbørs stiger årsinntekt med 0.33 enheter på log-skala. Dette tilsvarer 39% økning. Vi kan bruke Jamovi som kalkulator å legge inn en ny transform:\n=100 * (EXP($SOURCE) - 1)\nEn en ny variabel kan vi legge inn resultatet vi er interessert i å transformere og finner den prosentuelle økningen."
  },
  {
    "objectID": "02-statistisk-samvariasjon.html#variansanalyse",
    "href": "02-statistisk-samvariasjon.html#variansanalyse",
    "title": "3  Statistisk samvariasjon i dataanalyse",
    "section": "3.5 Variansanalyse",
    "text": "3.5 Variansanalyse\nThrane (2020) tar opp variansanalyse som et verktøy for samvariasjon når den uavhengige variabelen er kategorisk og den avhengige variabelen er numerisk kontinuerlig. I praksis stille vi spørsmål om en avhengig variabel variere sammen med en kategorisk, dette undersøkes ved å se på gjennomsnitt i hver gruppe og differenser mellom de. Teknisk sett så er variansanalyse en type regresjonsmodell (regresjonsmodellen er fleksibel) hvor vi undersøker hvordan dataene varierer (varians) mellom og innad kategorier/grupper, derav navnet variansanalys (Analysis of Variance, ANOVA på engelsk). Vi vil bruke denne modellen i kommende moduler i emnet."
  },
  {
    "objectID": "02-statistisk-samvariasjon.html#variansanalyse-i-jamovi",
    "href": "02-statistisk-samvariasjon.html#variansanalyse-i-jamovi",
    "title": "3  Statistisk samvariasjon i dataanalyse",
    "section": "3.6 Variansanalyse i Jamovi",
    "text": "3.6 Variansanalyse i Jamovi\nVi kan reprodusere analysen som presenteres i Tabell 3.2 i (Thrane 2020) ved å velge ANOVA-modulen i Jamovi, videre velger vi One-way ANOVA. Denne analysen gjennomføres over en kategorisk variabel, derav navnet “en-veis variansanalyse”. Vi setter årsinntekt som avnhengig variabel (Dependent variable) og landslag som uavhengig variabel (Grouping variable).\nI analysen finner vi flere mulige valg. Under Variances har vi mulighet å velge om vi skal gjøre antagelse om lik eller ulik varians mellom grupper. Her er Welch’s one-way ANOVA å foretrekke. Denne metode for å beregne teststatistikken som blir brukt for å teste hypotesen (gjennomsnitt i gruppen skiller seg i fra hverandre), er mer robust. Vi risikerer til mindre grad å bli lurt av hypotesetesten (mer om dette senere i emnet).\nUnder Missing values velger vi hvordan vi håndterer observasjoner hvor vi savner data. Under Assumption Checks kan vi la Jamovi gjennomføre noen test for de antagelser som følger med analysen. Homogeneity test tester om variance er lik mellom grupper, hvis den ikke er det er Welch’s test et test som tar høyde for dette. Som i regresjonsanalysen kan vi se på en Q-Q plot som viser hvor nærme feilleddet (residualene) ligger en normalfordeling.\nUnder Additional Statistics finner vi muligheten å faktisk finne gjennomsnitt per gruppe. Her kan vi reprodusere Tabell 3.2 (Thrane 2020). Figuren 3.4 i (Thrane 2020) kan vi reprodusere under Exploration."
  },
  {
    "objectID": "02-statistisk-samvariasjon.html#krysstabulering",
    "href": "02-statistisk-samvariasjon.html#krysstabulering",
    "title": "3  Statistisk samvariasjon i dataanalyse",
    "section": "3.7 Krysstabulering",
    "text": "3.7 Krysstabulering\nANOVA og ordinær regresjonsanalyse kan ikke ha en kategorisk avhengig variabel (da kreves mer avanserte modeller). Her kan isteden bruke krysstabulering. Likt ANOVA og regresjonsmodellen kan krysstabuleringen knyttes mot statistiske test, vi vil snakke mer om disse senere i emnet.\nVi kan gjenskape Tabell 3.5 i (Thrane 2020) ved å åpne datasettet student_trening_1_2_3.csv i jamovi. Under modulen Frequencies finner vi Independet samples, \\(\\chi^2\\) test of association. Vi velger å sette kjønn i Rows og idrettslag i Columns. Under Cells kan vi velge å sette opp observerte antall under Counts og prosentandeler per rad, kolonne eller totalt under Percentages. Jamovi kan også gi deg informative figurer fra analysene som baserer seg på krysstabulering.\n\n\n\nThrane, Christer. 2020. Statistisk Dataanalyse På 1-2-3. Cappelen Damm."
  },
  {
    "objectID": "03-a-intro.html",
    "href": "03-a-intro.html",
    "title": "Kausalsammenheng",
    "section": "",
    "text": "Med statistiske verktøy kan vi estimere sammenhenger mellom variabler. For eksempel kan en t-test brukes for å si noe om forskjellen mellom to grupper, vi kan se på dette som en mulig sammenheng mellom gruppe og en utfallsvariabel. På en lignende måte kan en inndeling i flere grupper ha en sammenheng med en utfallsvariabel, noe som kan måles ved hjelp av en ANOVA-modell. En mer generell statistisk modell er regresjonsmodellen. Ved bruk av en regresjonsmodell kan vi måle sammenhengen mellom en eller flere uavhengige variabler og en avhengig variabel. Statistikken er full av modeller og metoder som måler sammenhenger.\nMen hvordan kan vi tolke sammenhenger? I vitenskapshistorien finnes flere eksempler på hvordan man argumenterer for at vi ikke kan si noe om en kausalsammenheng basert på en statistisk sammenheng. «Correlation does not imply causation» er en vanlig frase som brukes for å avferda sammenhenger som betydningsløse. Vi kan finne støtte for en slik forståelse, hver morgen (i hvert fall på en hverdag, og i hvert fall om høsten) når vekkerklokken din ringer står du opp og lager en kopp kaffe. Når du setter deg ned for å drikke kaffen stiger solen over horisonten. Men, det at du drikker kaffe får ikke solen til å gå opp. Her finnes ingen kausalsammenheng."
  },
  {
    "objectID": "03-kausalsammenheng.html#eksperiment-og-kvasieksperiment",
    "href": "03-kausalsammenheng.html#eksperiment-og-kvasieksperiment",
    "title": "5  Fra sammenheng til kausalitet",
    "section": "5.1 Eksperiment og kvasieksperiment",
    "text": "5.1 Eksperiment og kvasieksperiment\nEt eksperiment kan brukes til å sammenligne to typer av intervensjoner. Vi sammenligner disse intervensjonene i en definert gruppe. Denne gruppen, eller populasjonen, kan som et eksempel være idrettsutøvere, og intervensjonene kan være to forskjellige treningsprogrammer hvor et program er et nytt program (N) og det andre er hva man vanligvis bruker, en slags kontrollprogram (K). Vi ønsker med vårt eksperiment å si noe om effekten av N på gruppen idrettsutøvere. Vi rekrutterer en gruppe idrettsutøvere og deler inn dem i to grupper, N og K.\nFor å gjøre sammenligningen bestemmer vi en utfallsvariabel, i eksemplet passer det fint å måle løpehastighet i en 3000-m test. Vi lar utøverne løpe testen i forkant av studien, ved tid 1 (\\(t_1\\)), og etter studien, ved tid 2 (\\(t_2\\)). Vi kan nå beregne en forandringsskår (\\(\\delta\\)). Hvor mye forandret seg hvert enkelt individ fra \\(t_1\\) til \\(t_2\\)?\n\\[\\Delta = t_2 – t_1\\]\nI neste steg kan vi beregne effekten av N, det nye treningsprogrammet. For å beregne denne så trekker vi ifra forandringen i K (\\(\\Delta_K\\)) fra effekten av N (\\(\\Delta_N\\)), denne beregning gir oss den gjennomsnittlige intervensjonseffekten (GIE) av å gjennomføre N, sammenlignet med et kontrollprogram (K).\n\\[ \\Delta_N - \\Delta_K = \\text{GIE}\\]\nFor å si at den estimerte GIE er den kausale effekten av å gjennomføre N kreves noen grep og antagelser. Når vi delte inn deltakere i studien så må vi ta grep for å gi hvert deltakere samme sannsynlighet å ende opp i hver gruppe. Vi sikkerstille dette ved å randomisere forsøket. I et randomisert forsøk bruker man vanligvis et dataprogram som tilfeldig tildeler gruppetilhørighet til hvert individ. Inndelingen av gruppene påvirkes ikke forskerne, deltakerne eller andre faktorer som samtidig kan påvirke resultatene. Dette er en aspekt av forsøket som gjør at vi kan kalle det for et eksperiment. Et nærbeslektet design er en kvasieksperimentell studie. I en slik studie har noe ytterligere påvirket gruppeinndelingen og dermed påvirket effekten som er utfallet av studien.\nEn annen effekt som kan påvirke resultatene i studien er om den tilfeldige inndelingen i grupper gir en overvekt av dårlig trente utøvere i den ene gruppen. En dårlig trent individ kan forventes svare bedre på trening og hvis alle disse er samlet i en gruppe forsvinner eller forsterkes effekten av intervensjonen. For å unngå en slik situasjon kan vi gjennomføre en oppdeling av deltakerne i forkant av intervensjonen basert på noen karakteristikk som vi ser som viktige for utfallet i studien. Oppdelingen kan gi oss par som er sammenligningsbare, randomiseringen skjer seden parvis hvor hvert individ i hvert par har samme sannsynlighet for å ende opp i hver enkelt gruppe.\nNår en gruppe deltakere i et forskningsprosjekt er tilstrekkelig stor er sannsynligheten liten for å få ubalanserte grupper med hensyn til utfallet i studien som i eksemplet er treningseffekten. Vi veit ikke heller den forventede effekten i hvert individ noe som gjør matching vanskelig. Når vi fordeler deltakere på intervensjonsgruppene ved hjelp av en tilfeldig prosess så gjør vi også at kilder til systematisk variasjon blir tilfeldig fordelt, noe som gir mulighet å si at effekt av N er kausal.\n\n\n\n\n\nFigur 5.1. Treningsprogrammet (N) påvirker hastighet (H) i et 3000-m løpetest."
  },
  {
    "objectID": "04-induktiv-statistikk.html#populasjon-og-utvalg-målet-med-statistisk-inferens",
    "href": "04-induktiv-statistikk.html#populasjon-og-utvalg-målet-med-statistisk-inferens",
    "title": "7  Statistisk inferens",
    "section": "7.1 Populasjon og utvalg, målet med statistisk inferens",
    "text": "7.1 Populasjon og utvalg, målet med statistisk inferens\nEn populasjon i statistikken er som nevnes i (Thrane 2020) en samling av alle mulige observasjoner med et sett med spesifikke karakteristikker. Denne definisjonen brukes på litt forskjellige måter, men for at den ska være av betydelse i vår videre diskusjon bør den si noe om hva vi ønsker å måle og i hvilken kontekst. Kanskje er vi interesserte i IQ (hva) hos menn og kvinner mellom 18 og 65 år i Norge (kontekst). Vi har ikke mulighet å undersøke hele populasjonen, men et lite utvalg. Målet med å undersøke et utvalg er å si noe om populasjonen. I utvalget kan vi beregne noen deskriptive statistikker som gjennomsnitt og spredning. Samtidig som dette sier noe om dataene som vi har er det også et estimat av parametere i populasjonen. I den enkleste forståelsen av begrepet modell, kan gjennomsnitt og spredning fungere som en modell av populasjonen. Basert på disse kan vi trekke slutninger om populasjonen.\n\n7.1.1 Utvalg og generalisering\nFor å trekke korrekte slutninger om en populasjon kreves at utvalg et representativt for populasjonen. Når utvalget representerer den populasjon man ønsker å undersøke kan man gjøre den generalisering som det innebærer å trekke konklusjoner om populasjonen basert på utvalget. Ideelt sett trekkes et utvalg fra populasjonen helt tilfeldig. Dette gir en garanti mot at utvalget ikke skiller seg fra populasjonen i noen viktige karakteristikker. I forskningen er dette i praktikken veldig vanskelig.\nTenkt deg at du ønsker å studere effekten av trening i den voksne norske befolkningen, vi ønsker å si generalisere resultater fra studien til hele befolkningen, menn, kvinner, unge, gamle, friske og individer som sliter med noen helseplager. Vi går ut i lokalavisen å sier at vi tenker gjennomføre en studie som bruker høyintensiv trening for å forbedre fysisk prestasjonsevne. Interesserte kan melde seg til studien ved å ringe eller sende en e-post. Denne rekrutteringsprosessen vil introdusere en karakteristikk i utvalget som ikke kan sies representere populasjonen, dette da individer som ønsker å gjennomføre høyintensiv trening melder seg til studien.\nHvis vi prøver å gjøre noe åt dette kan vi sende ut et påmeldingsskjema til la oss si 1000 privatadresser i Lillehammer. Vi vil fortsatt sitte igjen med et utvalg som ikke representerer populasjonen, men vi har nå mulighet å undersøke de som ikke melder seg på. Vi kan spørre de som ikke er interesserte i å delta hvorfor det er slik, dette kan si noe om hva utvalget representerer og hvor langt vi kan generalisere resultater fra studien.\nI praktikken er ulike former av bekvemmelighetsutvalg trolig den mest forekommende formen for utvalg i mye av forskningen. Med bekvemmelighetsutvalg mener vi et utvalg som vi har tilgang til. En vel undersøkt populasjon innen fysiologisk idrettsforskning er mannlige studenter ved idrettsutdanninger."
  },
  {
    "objectID": "04-induktiv-statistikk.html#utvalg-og-estimering",
    "href": "04-induktiv-statistikk.html#utvalg-og-estimering",
    "title": "7  Statistisk inferens",
    "section": "7.2 Utvalg og estimering",
    "text": "7.2 Utvalg og estimering\nNår vi har et utvalg så kan vi måle noe og derved estimere den sanne verdien1 i populasjonen. Da vi ønsker å si noe om den sanne verdien sier dette også noe om at vi kan være mer eller mindre sikre på et estimat, og vi kan ha feil. Vi må ha verktøy som tar hensyn til begge disse konseptene som er tett sammenkoblet nemlig, presisjon og feilrate. Vi kan starte med å konstatere at all estimering gjøres med usikkerhet, men hvordan kan vi si noe om usikkerheten. Vi vil gjennomføre et tankeeksperiment.1 I frekventisme ser vi på populasjonsparameteren som en (teoretisk) gitt verdi som ikke forandres.\nI frekventisme er det mulig å tenke seg at vi i teorien kan trekke flere uavhengige utvalg fra en populasjon. La oss gjøre dette, vi trekker flere utvalg med størrelse 10 (10 observasjoner). Fra hvert utvalg kan vi beregne gjennomsnitt og standardavvik. Vi legger sammen gjennomsnittene fra de mange utvalgene i en ny fordeling, en fordeling av gjennomsnitt fra utvalg. Det viser seg at en fordeling av gjennomsnitt har det samme gjennomsnittet som populasjonen og at spredningen (standardavviket) i denne fordelingen bestemmes av størrelsen på utvalgene. Standardfeilen er spredningen i en fordeling av gjennomsnitt fra flere utvalg. Standardfeilen (SE, standard error på engelsk) beregnes som\n\\[SE = \\frac{\\sigma}{\\sqrt{n}}\\] hvor \\(\\sigma\\) er standardavviket i populasjonen og \\(n\\) er størrelsen på utvalget. Problemet her er at vi ikke kjenner \\(\\sigma\\), isteden vil vi bruke det estimerte standardavviket fra et utvalg for å gjennomføre beregning.\n\\[SE = \\frac{s}{\\sqrt{n}}\\] Det viser seg at når vi trekker flere utvalg så vil vi det lange løp, i gjennomsnitt, få standardfeil i utvalgene som tilsvarer standardavviket i utvalgsfordelingen. Dette er fantastisk, og grunnen til at vi kan si noe om populasjonen basert på et utvalg.\nSom vi kan se i beregningen av standardfeilen så er den avhengig av utvalgsstørrelsen. Når utvalgsstørrelsen (\\(n\\)) er større blir standardfeilen mindre. Det betyr at fordelingen av gjennomsnitt fra utvalgene vil være tettere samlet kring den sanne verdien, populasjonsgjennomsnittet, når utvalgsstørrelsen er større.\nEn annen observasjon som kan gjøres av utvalgsfordelingen er at den vil ha en lignende form uansett underliggende populasjonsfordeling. Fordelingen vil ligne på det som kalles normalfordeling. Normalfordelingen bestemmes av et gjennomsnitt og et standardavvik. Dette betyr at vi i mange tilfeller kan bruke estimerte gjennomsnitt og standardavvik for å lage en modell av utvalgsfordelingen. For enda bedre presisjon i estimeringen av en utvalgsfordeling når utvalgsstørrelsen er liten brukes en \\(t\\)-fordeling. Denne fordelingen tar også hensyn til utvalgsstørrelsen. Da utvalgsfordelingen har kjente egenskaper (normalfordelingen og \\(t\\)-fordelingen) så kan vi bruke denne for å si noe om hvordan vi ser for oss at en teoretisk fordeling av flere gjennomsnitt ser ut. Dette er grunnen for konfidensintervaller.\n\n7.2.1 Konfidensintervaller\nEt konfidensintervall tar utgangspunkt i den estimerte utvalgsfordelingen. Vi lager et intervall som fanger in en gitt prosent av alle mulige gjennomsnitt fra en teoretisk samling av utvalg. Av tradisjon brukes et ofte et 95% intervall. Et 95% intervall gir oss et intervall av gjennomsnittsverdier som inneholder 95% av alle utvalg ved en repeterte utvalgsprosess. Dette sier også noe om definisjonen av konfidensintervallet. Ved repeterte utvalg inneholder konfidensintervallene populasjonsgjennomsnittet i 95% av tilfellene. Dessverre vet vi ikke om et spesifikt intervall gjør det eller ikke. Her finnes det fare for at definisjonen i (Thrane 2020, sid. 92) gir en feilaktig bilde av konfidensintervallet. Det er altså ikke slik at et konfidensintervall i seg har en sikkerhet. Et enkelt intervall inneholder populasjonsgjennomsnittet, eller ikke. Prosenttallet som vi setter på intervallet sier noe om prosessen med repeterte utvalg. Det sier noe om hvor ofte vi tar feil ved repeterte utvalg fra den samme populasjonen.\n\nThrane, Christer. 2020. Statistisk Dataanalyse På 1-2-3. Cappelen Damm.\nHvis vi forandrer frekvensen med hvilken vi kan a feil fra 5% (95% konfidensintervall) til 10% (90% konfidensintervall) vil intervallet bli mindre. Altså ved en større risk at enkelte konfidensintervall ikke inneholder populasjonsgjennomsnittet får vi et intervall som bedre beskriver populasjonsgjennomsnittet (hvis vi har rett konfidensintervall). Vi kan gå andre veien også, et 99% konfidensintervall er et intervall som holder flere teoretiske gjennomsnitt som mulige populasjonsgjennomsnitt, dette intervallet kommer fra en samling intervaller hvor bare 1 av 10 ikke finner det sanne gjennomsnittet. Igjen, vi vet ikke hvis vi har et intervall som er rett eller galt.\nUtvalgsstørrelsen vil påvirke bredden på intervallene, men ved repeterte utvalg vil vi til tross av dette ha feil i en gitt andel av fallene."
  },
  {
    "objectID": "04-induktiv-statistikk.html#hypotesetesting-og-p-verdier",
    "href": "04-induktiv-statistikk.html#hypotesetesting-og-p-verdier",
    "title": "7  Statistisk inferens",
    "section": "7.3 Hypotesetesting og p-verdier",
    "text": "7.3 Hypotesetesting og p-verdier\nI statistikken har vi mulighet å teste hvor kompatible våre data er med en gitt hypotese. Vi kan formulere en hypotese for kontinuerlig data gjennom å velge et tall som vi tester mot. Den frekventistiske statistikken bruker nullhypoteser og rundt denne hypotesen bygger vi opp en estimert utvalgsfordeling. Vi kan nå besvare spørsmålet: Gitt att nullhypotesen er sann, hvor sannsynlig er det at vi får et resultat så ekstremt som det vi observerer, eller enda mer ekstremt?\nDenne definisjonen er dessverre ikke helt intuitiv, vi lager et eksempel under for å bedre forstå den. La oss si at vi gjennomfører et forsøk hvor vi studerer effekten av fysisk aktivitet på blodtrykk. De rekrutterte deltakerne som i utgangpunkt har høyt blodtrykk fordeles tilfeldig (randomisert) til to grupper. Gruppe A får ingen retningslinjer for fysisk aktivitet, gruppe B får oppfølging fra en personlig trener. Etter en intervensjonsperiode tester vi blodtrykket.\nFra studien er det mulig å formulere to hypoteser, en nullhypotese sier at det ikke er noen forskjell mellom gruppene. Den alternative hypotesen sier derimot at det er en forskjell i blodtrykk mellom gruppene etter intervensjonsperioden. Filosofiske argumenter gir at det er vanskelig å bevise en hypotese men enklere å motbevise. I statistikken bruker vi vanligvis nullhypotesen, og vi tester mot den. Vi setter opp testet sånn at om testresultatet er tilstrekkelig ekstremt gitt at nullhypotesen er sann så avkrefter vi den, eller finner den mindre trolig enn den alternative hypotesen.\nVi samler inn data og ser en XX forskjell mellom gruppene i systolisk blodtrykk etter intervensjonen. Hvis nullhypotesen er sann, hvor usannsynlig er det observerte resultatet? For å etterligne en nullhypotese skaper vi en kunstig utvalgsfordeling under nullhypotesen. Denne fordelingen lager vi gjennom å gi gruppetilhørighet til våre observasjoner helt tilfeldig, 10 000 ganger. Vi trekker altså tilfeldig deltakere og plasserer de i to grupper. Hver gang beregner vi et gjennomsnitt mellom gruppene som nå er en blanding av individer fra de faktiske intervensjonsgruppene. Gjennomsnittene samler vi opp og så beregner vi hvor mange gjennomsnitt som er så ekstreme eller enda mer ekstreme sammenlignet med det observerte gjennomsnittet fra intervensjonen. Vi sammenligner altså resultatet fra intervensjonen med gjennomsnitt som er mulige hvis tilfeldigheter og ikke intervensjonen bestemmer gruppene. Denne teknikken kalles for permutasjonstest.\nDet viser seg at bare XX% av gjennomsnittene er mer ekstreme enn det gjennomsnitt vi fikk fra intervensjonen. Er dette nok for å forkaste nullhypotesen. Hvis vi setter grensen på XX% kan vi si at vi i det lange løp (flere repeterte studier med den samme statistiske tilnærmingen) vil forkaste nullhypotesen, til tross for at den er sann i XX% av tilfellene. Å gjøre denne feilen kalles for et Type-1 feil."
  },
  {
    "objectID": "04-induktiv-statistikk.html#type-2-feil-statistisk-styrke-og-utvalgsstørrelser",
    "href": "04-induktiv-statistikk.html#type-2-feil-statistisk-styrke-og-utvalgsstørrelser",
    "title": "7  Statistisk inferens",
    "section": "7.4 Type 2 feil, statistisk styrke og utvalgsstørrelser",
    "text": "7.4 Type 2 feil, statistisk styrke og utvalgsstørrelser\nSå langt vet vi at vi kan gjøre en type 1 feil ved å forkaste nullhypotesen til tross for at den er riktig. Den frekventisktiske statistikken er opptatt av å kontrollere denne feilen, vi ønsker statistiske tester som har en gitt feil-rate i det lange løp (over flere lignende, uavhengige studier). I tillegg til type 1 feil kan vi også gjøre en annen feil ved å ikke forkaste nullhypotesen til tross for at en alternativ hypotese er sann. Denne feilen kalles for type-2 feil og den krever litt mer arbeid fra oss som skal analysere dataene. Vi kan sette opp de to typene feil i en tabell som under.\n\n\n\n\n\n\n\n\nNullhypotesen er…\nSann\nFalsk\n\n\n\n\nForkasted\nType-1 feil\nRiktig avgjørelse\n\n\nIkke forkasted\nRiktig avgjørelse\nType-2 feil\n\n\n\nI et scenario med to grupper som vi ønsker å sammenligne har vi formulert en nullhypotese som sier at det ikke finnes en forskjell mellom gruppene på populasjonsnivå. Husk at med statistisk inferens ønsker å si noe om data som vi ikke har observert (populasjonen) basert på data som vi har observert (utvalget). Før vi innhenter data formulerer vi også en alternativ hypotese. Vi lager denne alternative hypotesen basert på noen fakta vi allerede har om problemet. La oss ta fysisk aktivitet og blodtrykk som eksempel igjen.\nEn forandring i systolisk blodtrykk etter en behandling så stor som 5-10 mmHg kan sies være den minste forskjellen som er klinisk betydningsfull. Her kan vi argumentere for at en senkning av blodtrykk med 5-10 mmHg kreves for at en individ skal oppleve helsefordeler med behandlingen. Vi bruker 10 mmHg for å etablere en alternativ hypotese til nullhypotesen. Vi ønsker nå en statistisk test som oppdager denne forskjellen mellom to grupper, om den faktisk finnes. Evnen til en statistisk test å forkaste nullhypotesen til fordel for den alternative hypotesen kalles for statistisk styrke. Den statistiske styrken defineres som en minus den forventede raten med hvilken vi gjør type 2 feil (\\(1-\\beta\\)).\nI populasjonen som vi ønsker å undersøke er den gjennomsnittlige systoliske blotrykken 135 mmHg med en standardavvik på 20 mmHg. Vår alternative hypotese er at fysisk aktivitet senker blodtrykket med 10 mmHg. Disse tallene kan vi bruke for å beregne hvilken utvalgsstørrelse som gir en gitt statistisk styrke. Som et første steg trenger vi en standardisert effektstørrelse (\\(d\\)), denne er \\[d = \\frac{H_a}{SD} = \\frac{10}{20} = 0.5\\] En standardisert effektstørrelse er en måte å beskrive en effekt i termer av variasjonen. Hvor stor er effekten i forhold til den gjennomsnittlige variasjonen i populasjonen? Neste steg blir å bestemme hvilken statistisk styrke og hvor stor risiko for type 1 feil vi ønsker i testen. Her kan vi bruke en argumentasjon som går ut på at en type 1 feil er alvorligere enn type 2 feil. La oss si 4 ganger alvorligere, hvis vi ikke ønsker å gjøre en type 1 feil mer enn i 5% av repeterte studier kan vi leve med risikoen å gjøre en type 2 feil som er \\(5\\% \\times 4 = 20\\%\\).\nFor å til slutt beregne en utvalgsstørrelse har vi å følgende parameterer | | | |— | —| |Effektstørrelse | 0.5| |Risiko for type 1 feil (\\(\\alpha\\))| 5%| |Risiko for type 2 feil (\\(\\beta\\))| 20%| |Statistisk styrke (\\(1-\\beta\\))| 0.8|\nVi ønsker å gjøre en sammenligning mellom to uavhengige grupper og vi tillater at nullhypotesen kan forkastes i to retninger da trening i teorien kan gi lavere og høyere blodtrykk. Dette spesifiserer den statistiske testen som skal brukes (tosidig t-test med uavhengige grupper). Med denne informasjonen kan vi bruke Jamovi for å beregne utvalgsstørrelse.\n\n7.4.1 Mer om effektstørrelser\nTidligere har vi snakket om sammenhenger mellom variabler og hvordan vi kan måle disse. I de fall vi ønsker å sammenligne to grupper undersøker vi om det finnes en sammenheng mellom gruppe og den avhengige variabelen. Det kan være enklere å si det sånn at vi ønsker å undersøke forskjellen mellom gruppene. En effekt i denne sammenhengen kan beskrives på flere måter, som en absolutt forskjell (eks. 10 mmHg), som en forskjell relativ till en utgangsverdi (eks. \\(10/135 = 0.74 = 7.4\\%\\)) eller som en forskjell standardisert till standardavviket i målevariabelen (\\(10/20 = 0.5\\)). Den standardiserte effektstørrelsen kalles også for Cohen’s \\(d\\) etter en kjent statistiker og psykolog.\nEn standardisert effektstørrelse kan sammenlignes mellom studier og målevariabler. Vanligvis (etter beskrivning av Cohen(cohenStatisticalPowerAnalysis2013?)) beskriver man en effektstørrelse som liten hvis \\(d = 0.2\\), medium ved \\(d=0.5\\) og stor ved \\(d=0.8\\). En standardisert effektstørrelse kan også konverteres til forskjellige skaler. En medium Cohen’s \\(d\\) (0.5) kan for eksempel transformeres til en korrelasjonskoeffisient \\(r= 0.243\\). Dette gjør at standardiserte effektstørrelser blir brukt i meta-analyser hvor flere studier settes sammen for å undersøke et gitt fenomen.\nI sammenligning av to gjennomsnitt har effektstørrelsen en sammenheng med p-verdien som er avhengig av utvalgsstørrelse. Vid en gitt utvalgsstørrelse synker p-verdien når effektstørrelsen blir større."
  },
  {
    "objectID": "04-induktiv-statistikk.html#statistiske-tester-studiedesign-og-utvalg",
    "href": "04-induktiv-statistikk.html#statistiske-tester-studiedesign-og-utvalg",
    "title": "7  Statistisk inferens",
    "section": "7.5 Statistiske tester, studiedesign og utvalg",
    "text": "7.5 Statistiske tester, studiedesign og utvalg\nI flere eksempler har vi brukt data fra observasjonsstudier. I disse studiene samler vi inn data fra et utvalg og undersøker sammenhenger mellom variabler. Fra disse studiene er det typisk vanskelig å trekke konklusjoner om hva som ligger bak en observert effekt. Resultater fra observasjonsstudier kan brukes til å bedre forstå kausale sammenhenger, men dette krever en teoretisk modell og at vi måler andre variabler som kan tenkes influere sammenhenger mellom to variabler som vi er interesserte i. Til sammen kan disse brukes for å fastslå årsakssammenhenger.\nI et eksperiment trenger vi ikke å lage de samme teoretiske og statistiske modellene for å forstå sammenhenger, eller for eksempel, forskjeller mellom to grupper. Det som kreves er at faktorer som kan influere resultatene, kjente og ukjente, blir tilfeldig fordelt mellom de eksperimentelle gruppene/behandlingene. På den måten kan vi si at effekten av intervensjonen er den effekt som skiller gruppene åt og ikke noen annen faktor som blir introdusert i eksperimentet. Da en tilfeldig prosess ligger til grunn for inndeling av deltakere i forskjellige grupper er også resultatene til større grad generaliserbare til nye individer fra den samme populasjonen. I et eksperiment ønsker vi derfor å kontrollere mulige faktorer ved å tilfeldig allokere forsøkspersoner til eksperimentelle grupper, også kalt randomisering.\nDet finnes flere ulike varianter av randomisering som kan tilpasses forskjellige studiedesigner. Målet er å gi for eksempel deltakere like stor sannsynlighet for å deles inn i forskjellige grupper. Til tross for at vi bruker randomisering kan tilfeldigheter ha stor betydelse for resultatene i eksperimentelle studier. Dette særlig i små studier hvor tilfeldig variasjon i utvalget kan påvirke resultatene. Vi kan forstå dette ved å tenke på en studie hvor seks deltakere randomiseres til to grupper. I populasjonen finnes en faktor som har stor betydelse for resultatene i studien hos en av seks personer. I vår studie trekker vi et utvalg som direkte avspeiler populasjonen, en deltaker er bærer av den betydningsfulle faktoren. Til tross for randomisering så finnes ingen annen måte å fordele individet som har denne faktoren, og de som ikke har den på en ubalansert måte. En gruppe vil få denne faktoren. Hvis vi rekrutterer et større utvalg vil randomiseringen balansere faktoren mellom gruppene.\nEffekten av små studier kan ha stor betydelse for hvordan vi toker resultater fra studier. Det viser seg at om vi simulerer studier med få antall deltakere fra populasjoner med kjente effektstørrelser vil små studier (gruppestørrelser 5-25 individer) som regel gi oss flere estimat på effekter som er utrolige. Her finnes en fare i å tolke en stor effektstørrelse som betydningsfull når p-verdien gir beskjed om at vi bør være skeptiske. P-verdien (og t-verdien) tar høyde for en liten utvalgsstørrelse. Når vi har få deltakere i en studie vil halene på en t-fordeling inneholde mer masse. Ved en lignende effektstørrelse vil vi derfor beregne en mer konservativ (skeptisk) p-verdi. Når vi ikke har en effekt i populasjonen og simulerer studier fra disse beskytter p-verdien fra å forkaste nullhypotesen, vi vil bare ha feil i 5% av repeterte studier når vi setter dette som grensen for testene. Med få deltakere vil vi ikke finne effekten som finnes i populasjonen. Dette betyr at p-verdien ikke er avhengig av antall forsøkspersoner i en studie, med den statistiske styrken er det."
  },
  {
    "objectID": "05-formidling.html#presentere-statistiske-analyser",
    "href": "05-formidling.html#presentere-statistiske-analyser",
    "title": "9  En arbeidsflyt for statistisk analyse i Jamovi",
    "section": "9.1 Presentere statistiske analyser",
    "text": "9.1 Presentere statistiske analyser\nEn statistisk analyse bør presenteres til ditt publikum på en måte som gjør det klart hva din hensikt med presentasjonen er. Vi har i dette emnet forenklet snakket om presentasjoner som er deskriptive (beskrivende) og som har som hensikt å trekke slutninger om en populasjon basert på et utvalg (statistisk inferens). Vi kan legge til to kategorier her for en mer detaljert syn på statistisk inferens:\n\nEn analyse kan bygge på hypotesetesting. En problemstilling formuleres i forkant av analysearbeidet, den statistiske analysen gir støtte eller forkaster en nullhypotese.\nEn analyse kan være eksplorativ. Vi ønsker fortsatt å si noe om en populasjon basert på et utvalg, problemstillinger kan formuleres i forkant av analysen, men dataene er ikke nødvendigvis innsamlet med denne hensikten i tankene.\n\nI begge er det meget viktig å beskrive hva som er avhengig variabel, hva er det du ønsker å beskrive eller trekke slutninger om? I tillegg til de variabler som kreves for å angripe din problemstilling finnes det muligens flere variabler som du bruker for å beskrive datasettet, utvalget eller populasjonen. Du bør gjøre det klart for ditt publikum hvordan disse henger sammen og hvorfor de presenteres.\nDet finnes flere guider for hvordan man presenterer statistiske resultater. En meget brukt guide er den som publiseres av American Psychological Association (APA), en forkortet versjon finner dere her. Å følge en guide kan gi fordeler, men du bør også tenke på hva du ønsker å formidle. I eksemplet under beskriver vi forskjellen mellom grupper i utvalget og hva vi tror om forskjellen mellom grupper i populasjonen.\n\nSI oppviste en økning i VO2maks som var 281 ml \\(\\times\\) min-1 større enn LI (95% KI: [53, 507], t(15) = 2.64, p = 0.019).\n\nVi presenterer altså beskrivende statistikk hva gjelder utvalget sammen med konfidensintervaller og resultatet fra en t-test som gir en indikasjon på hva vi tror om gjennomsnittet i populasjonen ( konfidensintervall) og hvor sannsynlig det observerte resultatet eller et enda mer ekstremt resultat er hvis nullhypotesen er sann (t og p-verdier). Vi kan tenke oss å presentere ytterligere statistikker fra testen så som effekt størrelse.\nHvorfor presentere t sammen med p? Vi ønsker å vise at vi er å stole på, en gitt t-verdi bør samsvare med en p-verdi. Se f.eks. her for en kalkulator for t og p. En annen hensikt er å vise effekten i testen i standardiserte enheter, t-verdien beregnes som gjennomsnittlig forskjell delt på standardfeilen for forskjellen (\\(t = \\frac{x_1 - x_2}{SE(x_1 - x_2)}\\)). Vi får altså vite hvor mange standardfeil som skiller to gjennomsnitt. Vi ser også retningen på effekten (negativ eller positiv).\nNår vi presenterer resultater fra statistiske tester som er mer avanserte kan en tabell hjelpe. En regresjonstabell gir oss all informasjon som kreves for å presentere resultater. Legg merke til at Thrane presenterer en noe forenklet tabell. En regresjonstabell fra jamovi inneholder flere elementer som kan bidra til tolking av resultatene. En noe mer avansert modell for sammenligning av VO2maks etter en intervensjon som ble presentert som en t-test på differenser over kan være en ANCOVA modell. ANCOVA står for Analysis of Co-Variance. Her analyseres en kontinuerlig variabel som avhengig variabel sammen med en kategorisk variabel og kontinuerlig variabel som uavhengig variabel. Målet er å estimere forskjell i verdier post-intervensjon når vi kontrollerer for pre-intervensjons verdier. I tabellen under presentere resultater fra denne analysen.\n\n\n\n\n\n\n\n\n\n\n\n\nPredictor\nEstimate\nSE\n95% CI Lower\n95% CI Upper\nt\np\n\n\n\n\nIntercept ᵃ\n553.56\n562.68\n-653.27\n1760.39\n0.98\n0.3419\n\n\npre\n0.87\n0.11\n0.65\n1.10\n8.23\n9.87e-7\n\n\ngroup:\n \n \n \n \n \n \n\n\nSI – LI\n275.22\n104.89\n50.25\n500.19\n2.62\n0.0200\n\n\nᵃ Represents reference level\n\n\n\n\n\n\n\n\n\nI fall da vi bare ønsker å gi leseren estimatet vi er interesserte i, forskjell mellom grupper etter intervensjonen, kan vi skrive:\n\nEtter intervensjonen var VO2maks 275 ml \\(\\times\\) min-1 høyere i SI-gruppen sammenlignet med LI når vi kontrollerer for pre-intervensjonsverdier (95% KI: [50, 500], t(14) = 2.62, p = 0.02, se tabell 2 for en helhetlig regresjonstabell).\n\nVi henviser till tabell 2 for en komplett tabell med alle estimatene.\nNår du har mulighet, komplettere gjerne dine analyser med en figur. I noen vitenskapelige tidsskrifter kreves det at individuelle datapunkter presenteres i figur når antallet observasjoner per gruppe er lavt. Dette er praksis som gjør rapporter mer transparente. Tenk på at figurer og tekst skal komplettere hverandre, presenter ikke de samme resultatene i en figure som i tekst. Hvis vi skaper en figur som viser forskjell mellom gruppene sammen med et konfidensintervall løfter vi vekk denne informasjonen fra teksten og henviser til figuren.\n\nEtter intervensjonen var VO2maks høyere i SI-gruppen sammenlignet med LI når vi kontrollerer for pre-intervensjonsverdier (se Figur 1, t(14) = 2.62, p = 0.02, se Tabell 2 for en helhetlig regresjonstabell).\n\nEt resultatkapittel inneholder som regel ikke noe tolkende utsagn annet en indikasjoner på størrelse og retning på effekter, beskrivende statistikk og resultater fra hypotesetester. Tolkningen legger man som regel inn i diskusjonen. Noen ganger kan det kreves at du hjelper leseren å forstå hva du presenterer, du bør då legge inn en ekstra setning som beskriver for eksempel hva du estimerer."
  },
  {
    "objectID": "05-formidling.html#beskrive-analyser-i-metode",
    "href": "05-formidling.html#beskrive-analyser-i-metode",
    "title": "9  En arbeidsflyt for statistisk analyse i Jamovi",
    "section": "9.2 Beskrive analyser i metode",
    "text": "9.2 Beskrive analyser i metode\nI et metodekapittel avslutter man ofte med å beskrive de metoder som blir brukt for å analysere dataene. Her bør vi beskrive hvert test som presenteres i resultatene. Vi kan gruppere noe ved å si at “differenser mellom pre- og post-intervensjon i VO2maks og sykkelprestasjon ble sammenlignet mellom grupper ved hjelp av uavhengige t-tester”. I neste setning ønsker vi å si noe om hvordan vi presenterer dataene. “Deskriptiv data blir presentert som gjennomsnitt og standardavvik (SD). Gruppesammenligninger presenteres som gjennomsnittlig forskjell, 95% konfidensintervall sammen med t og p-verdier fra t-tester.”\nI denne delen av rapporten er det lurt å være så eksplisitt som mulig, si hva du faktisk har gjort og hvordan du faktisk presenterer dataene.\nTil sist kan du fint si at “alle resultater, rådata og analysefiler finnes samlet i…”. Og henvise til deres mappe som inneholder deres analysearbeid."
  },
  {
    "objectID": "05-formidling.html#lese-statistiske-analyser",
    "href": "05-formidling.html#lese-statistiske-analyser",
    "title": "9  En arbeidsflyt for statistisk analyse i Jamovi",
    "section": "9.3 Lese statistiske analyser",
    "text": "9.3 Lese statistiske analyser\nVi har nå diskutert hvordan vi kan presentere resultater fra et analyseprosjekt. Vi kan bruke de to ledestjernene for å lage analyseprosjekter når vi leser arbeider også. Vi kan prøve å besvare følgende spørsmål: er analysene presenterte på en transparent måte? Kan jeg reprodusere analysene? Hvis svarene er JA på disse to spørsmål kan vi muligens legge mer troverdighet i de resultater som presenteres.\nVi har gjennom emnet diskutert hvordan vi kan lure oss selve med statistiske verktøy. Når resultatene fra en statistisk analyse tolkes og konklusjoner trekkes kreves at vi kan vedlikeholde en kritisk blikk på analysene. Vi kan prøve å besvare spørsmålet hvordan kan forfatterne lurt seg selve her? En analyse kan være både transparent og mulig å reprodusere, men konklusjonene bygger på at man tolket dataene og resultatene feil eller brukt statistiske modeller som ikke gir en riktig bilde av dataene (og verden). Det å tolke statistiske analyser fra denne synsvinkelen krever trening og en kritisk blikk. Thrane (2020) gir noen tips som omhandler for eksempel assosiasjon og kausalitet, absolutte og relative effekter og generalisering til forskjellige populasjoner.\n\nThrane, Christer. 2020. Statistisk Dataanalyse På 1-2-3. Cappelen Damm."
  },
  {
    "objectID": "05-formidling.html#vitenskapelige-skriving-en-strukturert-rapport",
    "href": "05-formidling.html#vitenskapelige-skriving-en-strukturert-rapport",
    "title": "9  En arbeidsflyt for statistisk analyse i Jamovi",
    "section": "9.4 Vitenskapelige skriving: En strukturert rapport",
    "text": "9.4 Vitenskapelige skriving: En strukturert rapport\nEn vitenskapelig rapport skiller seg på flere måter fra hvordan andre tekster skrives. En vitenskapelig rapport ønsker ofte å formidle kunnskap som baserer seg på data eller logikk på en måte som gir leseren den samme forståelsen av et fenomen som forfatteren av rapporten. Det finnes variasjoner av vitenskapelige tekster som for eksempel når forfatteren ønsker å formidle en mening i en vitenskapelig debatt.\nForskere og andre lesere av vitenskapelige tekster (studenter, trenere, helsearbeidere, politiker osv.) har ikke alltid så mye tid, derfor har det utviklet seg måter å strukturere rapporter på som gjører det enkelt å finne hva man søker etter. Disse strukturer skiller seg mellom ulike felt (f.eks. medisin, psykologi, litteraturvitenskap, sosiologi) og mellom ulike publiseringskanaler (f.eks. mellom ulike tidsskrifter). Men man kan se et felles mønster og dette mønster kan beskrives som\nIMR(o)D\nSom står for: Introduksjon, Metode, Resultat og Diskusjon.\nDenne strukturen er mye brukt i forskningsrapporter som formidler et eksperiment eller observasjoner. Men vi kan og bruke modellen når vi formidler oversikter over et felt gjennom en litteraturoversikt. I noen situasjoner er noen deler ikke nødvendige, for eksempel, når vi rapporterer et enkelt eksperiment med lite plass for tolking kan diskusjonen bli en mindre del eller forsvinne helt. Når vi skriver en tekst til et seminarium kan vi ta vekk metodedelen og resultatene og derved introdusere leseren til et felt følget av en diskusjon om feltet.\n\n9.4.1 Introduksjon\nHensikten med introduksjonen er å introdusere leseren til den resterende teksten. Vi skal her presentere noen fakta som er viktige for å sette resten av rapporten i en kontekst. Disse fakta bakkes opp av referanser/kilder som presenterer tidligere kunnskap for leseren. Denne første delen av introduksjonen kan sies være deskriptiv, eller beskrivende.\nNeste del av introduksjonen kan brukes får å presentere problemet som man ønsker å undersøke eller rapportere kring. Denne delen kan sies være analytisk. I et større vitenskapelig arbeid (f.eks. en bacheloroppgave) bruker vi denne delen får å formulere forskningsspørsmål eller hypoteser basert på tidligere forskning og kunnskapshull.\nI en større rapport kan man under introduksjonskapitlet og rapportere en mer omfattende litteraturgjennomgang.\nIntroduksjonen kan sies besvare spørsmålene: Hva er feltet? Hva er problemet? Hvorfor er det problemet?\nPrøv å unngå å motivere dine tekster med for eksempel «Hensikten med denne teksten er å besvare oppgaven i emnet…». Unngå også å bruk plass på «I introduksjonen vil jeg presentere en introduksjon til emnet…». Begge eksemplene over kan sies være deler i din tekst som beskriver teksten, fokusere istedenfor på å beskrive fenomenet du ønsker å fortelle leseren om.\n\n\n9.4.2 Metode\nUnder metode forventes man beskriv hvordan man gjennomfører sin studie. Denne kan beskrives som for eksempel et eksperiment, en observasjon, en litteraturgjennomgang. I en større rapport kan man fordele metodedelen over flere underkapittel som først gir en oversikt over studien følget av en detaljerte beskrivelser av hvordan forskjellige metoder har blitt gjennomført.\nMetoden skreves i fortid, når du rapporterer på et gjennomført eksperiment eller observasjon. Beskrivelsen skall være så pass detaljert at leseren selv kan gjennomføre eksperimentet. En detaljert beskrivelse av metoden gir leseren mulighet å bedømme hvor tilforlatelige resultatene er.\n\n\n9.4.3 Resultat\nHer besvares spørsmålet om hva som ble funnet i eksperimentet, observasjonen eller litteraturgjennomgangen. Resultatene kan være meget enkle gjennom for eksempel presentasjon av et gjennomsnitt og spredningsmål av en måling, eller meget komplekse gjennom presentasjon av flere målinger fra flere eksperimenter og statistiske modeller. Resultater er ofte presenterte i tekst, tabeller og figurer. Tabeller og figurer hjelper forfatteren å presentere mye data på en strukturert måte. Figurer og tabeller forteller leseren mer på begrenset plass sammenlignet med tekst. Men i teksten må du henvise til figurer og tabeller, ingen figurer eller tabeller får være ukommenterte. Tenk på teksten i resultatdelen som et gelender som leder leseren gjennom rapporten i en logisk orden. Med hånden stadig plassert på gelenderet har leseren mulighet å skjønne hva figurer og tabeller formidler og setter disse i kontekst. Tar du vekk gelenderet faller leseren mot en sikker død i en avgrunn av enkeltstående figurer og tabeller.\nHvis leseren selv hopper over gelenderet og prøver å skjønne tabeller og figurer uten din trygge ledsagelse så kan du fortsatt være en god forfatter gjennom å beskrive hva figurer og tabeller viser. En regel er at figurer og tabeller bør kunne leses for seg selv. En figurtekst bør inneholde tilstrekkelig informasjon for at leseren skal ha mulighet å skjønne hva den viser. Det samme gjelder tabeller.\n\n\n9.4.4 Diskusjon\nI diskusjonen forteller du leseren hva resultatene betyr, du gjør en tolkning av resultatene som du tidligere har presentert. Tolkningen binder sammen introduksjonen, metoden og resultatene. Du bør i diskusjonen i tillegg til å fortelle om tolkningen og beskrive hvorfor du syns resultatene kan tolkes på den måte du presenterer. Du kan ytterligere balansere denne beskrivelsen gjennom å vise leseren hvordan din studie er begrenset. I diskusjonen bør du også bruke referanser og kilder får alle utsagn som ikke bygger på presentasjonen i resultatdelen. Du kan ved hjelp av tidligere forskning forklara dine resultater og sette disse i rett kontekst.\nDin tolkning kan være feilaktig, men du bør velge et konsekvent spår som beskriver din forståelse av den data du presenterer. Du kan også presentere steg for å komme videre med et forskningsspørsmål.\nTil sist presenterer du en konklusjon som summerer opp rapporten. I noen tekster er rapporten et eget avsnitt eller kapitel men i kortere rapporter er konklusjonen en måte å avslutte diskusjonen på."
  },
  {
    "objectID": "05-formidling.html#paragrafer",
    "href": "05-formidling.html#paragrafer",
    "title": "9  En arbeidsflyt for statistisk analyse i Jamovi",
    "section": "9.5 Paragrafer",
    "text": "9.5 Paragrafer\nEn tekst kan deles opp i mindre stykker som kan sies være verktøy for å formidle dit budskap til leseren. En viktig bestanddel i en tekst er paragrafer. En paragraf starter med en setning som beskriver paragrafens tema, emne eller hensikt. Dette kan være et utsagn som for eksempel «laks er en fisk som er nyttig å spise». Temasetning følges av en eller flere setninger som gir støtte til påstanden eller temaet for paragrafen. En støttesetning kan være «Laksen inneholder mye nyttige fettsyrer samtidig som den er proteinrik». Til sist avsluttes paragrafen med en overgangssetning som ledere leseren videre til neste paragraf. En overgangssetning kan være «Laks kan derfor være del i et sundt kosthold som bidrar til god muskelhelse sammen med andre proteinrike livsmiddel». Den siste setningen, en overgangssetning kan konkludere noe samtidig som det ledere leseren in på neste tema (muskelhelse og proteinrike livsmiddel i dette eksemplet).\nEn tekst kan gis struktur gjennom att du starter nye paragrafer når du introduserer nye temaer. Hver paragraf kan bearbeides får å gis en viss grad av selvstendighet. Dette gir deg mulighet å flytte rundt paragrafer får å gi din tekst en logisk rekkefølge. Du kan og bruke paragrafer får å begrense din tekst. Gi deg selv en begrenset plass for å formidle noe, la oss si tre paragrafer for å skrive en introduksjon. Lag en liste over hva hver paragraf skal formidle (tema), sett opp noen punkter som er til støtte for ditt tema og lag til sist et punkt som beskriver hvordan du konkluderer paragrafen og hvordan den ledere leseren videre. Du har nå strukturert dine paragrafer, og derved også din tekst."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referanser",
    "section": "",
    "text": "Thrane, Christer. 2020. Statistisk Dataanalyse På 1-2-3.\nCappelen Damm.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of\nStatistical Software 59 (10). https://doi.org/10.18637/jss.v059.i10."
  }
]