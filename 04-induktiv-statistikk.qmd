---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Statistisk inferens {#sec-statistiskinferens}

Vi mennesker er gode på å trekke slutninger om hvordan verden fungerer basert på et begrenset antall observasjoner. Denne evne til å lage mentale modeller av verden kan sies være et særtrekk i mennesket som gjort det mulig å skape avanserte sivilisasjoner. En mental modell, eller forståelse av hvordan verden henger sammen gir grunnlag for å samhandle med den, og forandre den. Noen ganger går det dessverre galt, vår mentale modell representerer ikke verden og utfall blir ikke hva vi forventer.

Innen vitenskapen prøver vi å systematisere prosessen som leder frem til ny kunnskap. Flere forskjellige filosofier blir brukt for å unngå å trekke falske slutninger om verden basert på data. Den filosofiske og statistiske skole som trolig blir mest brukt innen vitenskapen i dag kalles for frekventisme. Denne modulen vil introdusere statistisk inferens med fokus på frekventisme. Statistisk inferens er det å trekke konklusjoner om en populasjon basert på et utvalg. Vi ønsker å si noe om noe vi ikke observerer, basert på et begrenset datautvalg.

## Populasjon, utvalg og målet med statistisk inferens
En populasjon i statistikken er som nevnes i @thrane_2020 en samling av alle mulige observasjoner med et sett med spesifikke karakteristikker. Denne definisjonen brukes på litt forskjellige måter, men for at den skal være av betydning i vår videre diskusjon bør den si noe om hva vi ønsker å måle og i hvilken kontekst. Kanskje er vi interesserte i IQ (*hva*) hos menn og kvinner mellom 18 og 65 år i Norge (*kontekst*). Vi har ikke mulighet å undersøke hele populasjonen, men et lite utvalg. Målet med å undersøke et utvalg er å si noe om populasjonen. I utvalget kan vi beregne noen deskriptive statistikker som gjennomsnitt og spredning. Samtidig som dette sier noe om dataene som vi har er det også et *estimat* av parametere i populasjonen. I den enkleste forståelsen av begrepet modell, kan gjennomsnitt og spredning fungere som en modell av populasjonen. Basert på disse kan vi trekke slutninger om populasjonen.

::: {.column-margin}
En *parameter* er en kvantitativ egenskap hos en *populasjon*. En *populasjon* er i sin tur en samling av mulige verdier med et sett av gitte egenskaper. En parameter hos populasjonen kan være dess gjennomsitt (iblant kalt $\mu$) eller standardavvik ($\sigma$). Når vi estimerer gjennsomnitt og standardavvik i et utvalg gir vi disse kvantiteterne andra symboler, $\bar{x}$ og $s$. Disse er estimater av populasjonsgjennomsnittet og standardavviket [@dodge_concise_2008].
:::


### Utvalg og generalisering
For å trekke korrekte slutninger om en populasjon kreves at utvalget er representativt for populasjonen. Når utvalget representerer den populasjon man ønsker å undersøke kan man gjøre den generalisering som det innebærer å trekke konklusjoner om populasjonen basert på utvalget. Ideelt sett trekkes et utvalg fra populasjonen helt tilfeldig. Dette gir en garanti mot at utvalget ikke skiller seg fra populasjonen i noen viktige karakteristikker. I forskningen er dette i praksis veldig vanskelig.

Tenkt deg at du ønsker å studere effekten av trening i den voksne norske befolkningen, vi ønsker å generalisere resultater fra studien til hele befolkningen, menn, kvinner, unge, gamle, friske og individer som sliter med noen helseplager. Vi går ut i lokalavisen å sier at vi gjennomfører en studie som bruker høyintensiv trening for å forbedre fysisk prestasjonsevne. Interesserte kan melde seg til studien ved å ringe eller sende en e-post. Denne rekrutteringen vil introdusere en karakteristikk i utvalget som ikke kan sies representere populasjonen, dette da individer som ønsker å gjennomføre høyintensiv trening melder seg til studien.

Hvis vi prøver å gjøre noe åt dette kan vi sende ut et påmeldingsskjema til la oss si 1000 privatadresser i Lillehammer. Vi vil fortsatt sitte igjen med et utvalg som ikke representerer populasjonen, men vi har nå mulighet å undersøke de som ikke melder seg på. Vi kan spørre de som ikke er interesserte i å delta hvorfor det er slik, dette kan si noe om hva utvalget representerer og hvor langt vi kan generalisere resultater fra studien. 

I praksis er ulike former av bekvemmelighetsutvalg trolig den vanligste formen for utvalg i mye av forskningen. Med bekvemmelighetsutvalg mener vi et utvalg som vi har tilgang til. En vel undersøkt populasjon innen fysiologisk idrettsforskning er mannlige studenter ved idrettsutdanninger.



## Utvalg og estimering
Når vi har et utvalg så kan vi måle noe og dermed estimere den *sanne verdien*[^1] i populasjonen. Da vi ønsker å si noe om *den sanne verdien* sier dette også noe om at vi kan være mer eller mindre sikre på et estimat, og vi kan ha feil. Vi må ha verktøy som tar hensyn til begge disse konseptene som er tett sammenkoblet nemlig, presisjon og feilrate. Vi kan starte med å konstatere at all estimering gjøres med usikkerhet, men hvordan kan vi si noe om usikkerheten. Vi vil nå gjennomføre et tankeeksperiment.


[^1]: I frekventisme ser vi på populasjonsparameteren som en (teoretisk) gitt verdi som ikke forandres.


I frekventisme er det mulig å tenke seg at vi i teorien kan trekke flere uavhengige utvalg fra en populasjon. La oss gjøre dette, vi trekker flere utvalg med størrelse 10 (10 observasjoner). Fra hvert utvalg kan vi beregne gjennomsnitt og standardavvik. Vi legger sammen gjennomsnittene fra de mange utvalgene i en ny fordeling, en fordeling av gjennomsnitt basert på utvalg fra en populasjon. Det viser seg at en fordeling av gjennomsnitt har det samme gjennomsnittet som populasjonen og at spredningen (standardavviket) i denne fordelingen bestemmes av størrelsen på utvalgene. Standardfeilen er spredningen i en fordeling av gjennomsnitt fra flere utvalg. Standardfeilen (SE, standard error på engelsk) beregnes som

$$SE = \frac{\sigma}{\sqrt{n}}$$
hvor $\sigma$ er standardavviket i populasjonen og $n$ er størrelsen på utvalget. Problemet her er at vi ikke kjenner $\sigma$, isteden vil vi bruke det estimerte standardavviket fra et utvalg for å gjennomføre beregning. 

$$SE = \frac{s}{\sqrt{n}}$$
Det viser seg at når vi trekker flere utvalg så vil vi i det lange løp, i gjennomsnitt, få standardfeil i utvalgene som tilsvarer standardavviket i utvalgsfordelingen. Dette er et fantastisk resultat, og grunnen til at vi kan si noe om populasjonen basert på et utvalg.

### Estimere et gjennomsnitt, et eksempel

I Norge 2022 ble 52026 fødsler registrert i [Medisinsk fødselsregister](https://statistikkbank.fhi.no/mfr/). Gjennomsnittet for fødselsvekt var 3485 gram og standardavviket var 587 gram. Vi kan si at vi dermed kjenner til disse egenskapene i populasjonen, men hvor godt hadde vi klart å estimere disse verdiene hvis vi hadde trukket et utvalg på 10 barn fra populasjonen. For å besvare det spørsmålet kan vi lage et eksperiment hvor vi trekker 1000 utvalg fra populasjonen og beregner gjennomsnitt i hvert utvalg. Den resulterende utvalgfordelingen vil gi et bilde av hvor godt vi kan estimere populasjonen basert på et utvalg. Som vi ser i @fig-birtwtutvalg, i panelet med utvalgsfordeling kan et gjennomsnitt forventes være så lite som mindre enn 3000 og så stort som større enn 4000 g. Hvis utvalgsstørrelsen istedenfor 10 hadde vært 100, ville vi sett at utvalgsfordelingen var mer samlet rundt gjennomsnittet. 

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-width: 8
#| label: fig-birtwtutvalg
#| fig-height: 8
#| fig-cap: "Vi trekker utvalg (n = 10) fra en populasjon av fødselsvekter. For hvert utvalg beregner vi gjennomsnitt og legger hvert gjennomsnitt til en ny fordeling, utvalgsfordelingen. I figuren ser vi tre eksempel på utvalg og de totalt tusen utvalgen som i dette fallet skaper utvalgsfordelingen. Utvalgsfordelingen tar en form som kan beskrives som en symmetrisk fordeling. Hvis vi fordelingen fra populasjonen med en utvalgsfordeling med forskjellige utvalgsstørrelser ser vi at populasjonen er har størst spredning og en utvalgsfordeling med flere observasjoner er mer samlet kring gjennomsnittet."


library(tidyverse); library(ggtext); library(cowplot)


px <- data.frame(x = c(0,1), y = c(0,1)) %>%
  

  
  ggplot(aes(x, y)) + 
  
    scale_x_continuous(limits = c(0, 1), breaks = NULL) +
  
  scale_y_continuous(limits = c(0, 1), breaks = NULL) +
  theme_void()


p1 <- ggplot(data = data.frame(x = c(3485 - (4*587), 3485 + (4*587))), aes(x)) +
  stat_function(fun = dnorm, n = 101, 
                args = list(mean = 3485, sd = 587)) + 
  ylab("") +
  scale_y_continuous(breaks = NULL) + 
    labs(x = "F&#248;dselsvekt (gram)", 
         title = "Populasjonen") +
  theme(panel.grid = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank(), 
        axis.title.x = element_markdown()) 


set.seed(1)
## data sets
d1 <- data.frame(x = rnorm(10, 3485, 587))
d2 <- data.frame(x = rnorm(10, 3485, 587))
d3 <- data.frame(x = rnorm(10, 3485, 587))



samp_plot_fun <- function(d = d1) {
  
  d %>%
  ggplot(aes(x)) + 
  geom_dotplot(fill = "lightblue") +
  
  annotate("text", x = mean(d$x), y = 0.6, 
           label = "Gjennomsnitt", 
           vjust = 0, 
           hjust = 0.5, size = 4) +  
  
  annotate("segment", x = mean(d$x), xend = mean(d$x), 
  y = 0.55, yend = 0.2, size = 0.5, 
  arrow = arrow(type = "closed", length = unit(0.1, "inches"))) +  
      
  
  ylab("") +
  labs(x = "F&#248;dselsvekt (gram)") +
    scale_x_continuous(limits = c(3485 - (4*587), 3485 + (4*587)), breaks = c(1000, 3500, 6000)) +
    scale_y_continuous(breaks = NULL, limits = c(0, 0.7)) +
  theme(panel.grid = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank(), 
        axis.title.x = element_blank(), 
        plot.background = element_rect(fill = NULL))
  
  
}


p2 <- samp_plot_fun(d1)
p3 <- samp_plot_fun(d2)
p4 <- samp_plot_fun(d3)


## Sample distribution plot


dsamp1 <- bind_rows(d1  %>% summarise(x = mean(x))%>% mutate(samp = "s1"), 
          d2  %>% summarise(x = mean(x))%>% mutate(samp = "s2"), 
          d3  %>% summarise(x = mean(x))%>% mutate(samp = "s3"))


p5 <- data.frame(x = rnorm(1000, 3485, 587/sqrt(10)), 
           samp = "all") %>%
  ggplot(aes(x, fill = factor(samp))) +

  
  geom_dotplot(binwidth = 25,
               dotsize = 2.4,
              stackratio = 1) +
  
  geom_dotplot(data = dsamp1, aes(x = x,fill = samp), 
               binwidth = 25, 
               stackratio = 1, 
               dotsize = 5.5) +
  

    scale_fill_manual(values = c("lightblue", "steelblue", "orchid", "green")) +
  
  ylab("") +
    scale_x_continuous(limits = c(3485 - (4*587), 3485 + (4*587))) +
  theme(panel.grid = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank(), 
        axis.title.x = element_blank(), 
        plot.background = element_rect(fill = NULL), 
        legend.position = "none") + 
  labs(title = "Utvalgsfordeling")


## Combine population and sample plots

p6 <- ggplot(data = data.frame(x = c(3485 - (4*587), 3485 + (4*587))), aes(x)) +
  # Population
  stat_function(fun = dnorm, n = 101, 
                args = list(mean = 3485, sd = 587)) + 
  # Sampling distribution n = 10
    stat_function(fun = dnorm, n = 101, 
                  color = "steelblue",
                args = list(mean = 3485, sd = 587/sqrt(10))) + 
  # Sampling distribution n = 100
      stat_function(fun = dnorm, n = 101, 
                  color = "orchid",
                args = list(mean = 3485, sd = 587/sqrt(100))) + 
  
  
  ylab("") +
  scale_y_continuous(breaks = NULL) + 
    labs(x = "F&#248;dselsvekt (gram)", 
         title = "Populasjonen og utvalgsfordelinger") +
  theme(panel.grid = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank(), 
        axis.title.x = element_markdown()) +
  annotate("text", 
           x = 1000, 
           hjust = 0,
           size = 4,
           y = c(0.001,0.0015, 0.002),
           color = c("black", "steelblue", "orchid"),
           label = c("Populasjon",
                     "Utvalg, n = 10", 
                     "Utvalg, n = 100")) 



px + 
  draw_plot(p1, x = 0.01, y = 0.6, width = 0.35, height = 0.4) +
  draw_plot(p2, x = 0.05, y = 0.41, width = 0.2, height = 0.2) +
  draw_plot(p3, x = 0.05, y = 0.21, width = 0.2, height = 0.2) +
  draw_plot(p4, x = 0.05, y = 0.01, width = 0.2, height = 0.2) +
  
  
  annotate("text", 
           x = 0.01, 
           hjust = 1,
           y = 0.61, 
           label = "n = 10") +
  
  annotate(
    'curve',
    x = c(0.03,0.03, 0.03), 
    y = c(0.62,0.62, 0.62),
    yend = c(0.51,0.31, 0.11),
    xend = c(0.06,0.06, 0.06),
    linewidth = 0.8,
    curvature = 0.3,
    arrow = arrow(length = unit(0.25, 'cm'), type = "closed")
  )  +
  
    annotate(
    'curve',
    x = c(0.25,0.25, 0.25), 
    y = c(0.51,0.31, 0.11),
    yend = c(0.31,0.30, 0.29),
    xend = c(0.35,0.35, 0.35),
    linewidth = 0.8,
    curvature = 0.1,
    color = c("steelblue", "orchid", "green"),
    arrow = arrow(length = unit(0.25, 'cm'), type = "closed")
  ) +
  
  annotate("richtext", 
           x = 0.35, 
           hjust = 1,
           fill = NA, label.color = NA, # remove background and outline
           label.padding = grid::unit(rep(0, 4), "pt"), # remove padding
           y = 0.12, 
           label = "&times;1000") +
  
  
  draw_plot(p5, x = 0.36, y = 0.05, width = 0.4, height = 0.45) +
  
  draw_plot(p6, x = 0.58, y = 0.5, width = 0.45, height = 0.55) +
  
  annotate(
    'curve',
    x = c(0.81), 
    y = c(0.31),
    yend = c(0.5),
    xend = c(0.85),
    linewidth = 0.8,
    curvature = 0.1,
    arrow = arrow(length = unit(0.25, 'cm'), type = "closed")
  ) 



```

Hva er da poenget med dette? I den frekventistiske statistikken tenker vi oss at vi gjør dette eksperimentet hver gang vi skal estimere en populasjonsparameter. Usikkerheten i estimatet representeres av spredningen i utvalgsfordelingen. Men i praksis gjør vi jo ikke dette eksperimentet, isteden estimerer vi en populasjonsparameter som gjennomsnittet en gang og bruker spredningen i utvalget for å også estimerer spredningen i utvalgsfordelingen.


## Estimering av spredningen i utvalgsfordelingen

Som vi kan se over i beregningen av standardfeilen så er den avhengig av utvalgsstørrelsen. Når utvalgsstørrelsen ($n$) er større blir standardfeilen mindre. Det betyr at fordelingen av gjennomsnitt fra utvalgene vil være tettere samlet kring den *sanne verdien*, populasjonsgjennomsnittet, når utvalgsstørrelsen er større. Vi så dette i @fig-birtwtutvalg.

En annen observasjon som kan gjøres av utvalgsfordelingen er at den vil ha en lignende form uansett underliggende populasjonsfordeling. Fordelingen vil ligne på det som kalles normalfordeling. Normalfordelingen bestemmes av et gjennomsnitt og et standardavvik. Dette betyr at vi i mange tilfeller kan bruke estimerte gjennomsnitt og standardavvik for å lage en modell av utvalgsfordelingen. 

::: {.column-margin}

For enda bedre presisjon i estimeringen av en utvalgsfordeling når utvalgsstørrelsen er liten brukes en $t$-fordeling. Denne fordelingen tar også hensyn til utvalgsstørrelsen. Da utvalgsfordelingen har kjente egenskaper (normalfordelingen og $t$-fordelingen) så kan vi bruke denne for å si noe om hvordan vi ser for oss at en teoretisk fordeling av flere gjennomsnitt ser ut.

:::

Men hvor sikre kan vi være på estimatet av spredningen i en utvalgsfordeling? Spredningen i utvalgsfordelingen er altså spredningen av for eksempel gjennomsnitt hvis vi hadde trukket flere utvalg fra den samme populasjonen og beregnet gjennomsnitt for hvert av dem. Vi estimerer denne spredningen ved å beregne standardfeilen (SE). Hvis vi bruker standardavviket i hvert utvalg som et estimat for standardavviket i populasjonen, så kan vi også beregne standardavviket i utvalgsfordelingen. Dette gjør vi, som vi allerede har sett ved å dele standardavviket i populasjonen på kvadratroten av utvalgsstørrelsen. Hvis vi så hadde gjort dette som et eksperimentet hvor vi beregner standardfeilen mange ganger, så ville vi kunne se at vi i gjennomsnitt, i de fleste tilfeller være veldig nærme den faktiske variasjonen (se @fig-utvalgse).




```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-height: 4.5
#| fig-width: 4
#| label: fig-utvalgse
#| fig-cap: "Fordeling av estimat av standardfeil fra en populasjon med gjennomsnitt 3485 og standardavvik 587 og utvalg med størrelse 10. Den röde streken indikerer den teoretiske standardfeilen bergnet fra populasjonen."


dat <- vector()

set.seed(12)

for(i in 1:1000) {
  
  dat[i] <-  sd(rnorm(10, 3485, 587)) / sqrt(10) 
  
  
  
}


data.frame(x = dat) %>%
  ggplot(aes(x)) + geom_dotplot(dotsize = 1, 
                                binwidth = 5, 
                                fill = "lightblue") + 
  geom_vline(xintercept = 587/sqrt(10), color = "red") +
  theme_classic() + labs(x = "Standardfeil") + 
  theme(axis.title.y = element_blank(), 
        axis.ticks.y = element_blank(), 
        axis.line.y = element_blank(), 
        axis.text.y = element_blank())






```

## Målet og problemet med statistisk inferens

Så hva er problemet? Vi kan altså estimerer verdier i populasjonen ved hjelp av utvalg, og er vi usikre så kan vi alltid lage et eksperiment hvor vi trekker flere utvalg? I praksis har vi bare et begrenset utvalg, vi har veldig sjelden flere enn et utvalg og aldri 1000. Vi må altså stole på at estimatene vi skaper ved hjelp av et utvalg gir en god representasjon av populasjonen. Men hvordan kan vi vite når vi faktisk har rett?

## Konfidensintervaller
Et konfidensintervall tar utgangspunkt i den estimerte utvalgsfordelingen. Basert på utvalgsfordelingen lager vi et intervall som fanger inn en gitt prosent av alle mulige gjennomsnitt fra en teoretisk samling av utvalg. Av tradisjon brukes ofte et 95% intervall. Et 95% intervall gir oss et intervall av gjennomsnittsverdier som inneholder 95% av alle utvalg ved en (teoretisk) repeterte utvalgsprosess. Dette sier også noe om definisjonen av konfidensintervallet. Ved repeterte utvalg inneholder konfidensintervallene populasjonsparameteren (for eksempel gjennomsnittet) i 95% av tilfellene. Dessverre vet vi ikke om et spesifikt intervall gjør det eller ikke. 

::: {.column-margin}
Man kan argumentere for at definisjonen i [@thrane_2020, sid. 92] gir en feilaktig bilde av konfidensintervallet. Det er altså ikke slik at et konfidensintervall i seg har en sikkerhet. Et enkelt intervall inneholder populasjonsparameteren, eller så inneholder det ikke parameteren. Prosenttallet som vi setter på intervallet sier noe om prosessen med repeterte utvalg. Det sier noe om hvor ofte vi tar feil ved repeterte utvalg fra den samme populasjonen.
:::

Hvis vi forandrer frekvensen med hvilken vi kan ha feil fra 5% (95% konfidensintervall) til 10% (90% konfidensintervall) vil intervallet bli mindre. Altså med en større risk at enkelte konfidensintervall ikke inneholder populasjonsparameteren får vi et intervall som bedre beskriver populasjonsparameteren (hvis vi har rett konfidensintervall). Vi kan gå andre veien også, et 99% konfidensintervall er et intervall som holder flere teoretiske verdier som mulige for populasjonsparameteren, dette intervallet kommer fra en samling intervaller hvor bare 1 av 100 ikke finner den sanne verdien. Igjen, vi vet ikke hvis vi har et intervall som er rett eller galt.

Utvalgsstørrelsen vil påvirke bredden på intervallene, men ved repeterte utvalg vil vi til tross av dette ha feil i en gitt andel av tilfellene.

### Beregne et konfidensintervall

For å beregne et konfidensintervall trenger vi et gjennomsnitt med tilhørende standardfeil og en funksjon som beskriver en sannsynlighetsfordeling. Vi har allerede snakket om normalfordelingen, dette er et eksempel på en sannsynlighetsfordeling. Normalfordelingen er en symmetrisk fordeling som beskrives av to parametere, gjennomsnitt og standardavvik. Vi er interessert i å bruke normalfordelingen for å skape et intervall som inkluderer, la oss si, 95% av alle mulige verdier, gitt at vi har et gjennomsnitt og en spredning (standardfeilen). 

$$\bar{x} \pm z_{\alpha/2} \times \frac{s}{\sqrt{n}}$$
I formelen over er $\bar{x}$ gjennomsnittet, $s$ standardavviket, $n$ antall observasjoner og $z_{\alpha/2}$ er kvantilen vi ønsker til en normalfordeling og den tilsvarende faktoren vi trenger for å fange denne kvantilen. For et 95% konfidensintervall er $z_{\alpha/2} = 1.96$. $\alpha$ er den parameter som bestemmer sannsynligheten for å gjøre feilen at ikke fange populasjonsparameteren ved repeterte utvalg. For et 95% konfidensintervall er $\alpha = 0.05$ og $\alpha/2 = 0.025$. $\alpha/2 = 0.025$ betyr i sin tur at vi lar 2.5% av sannsynlighetsmassen i endene av fordelingen (halene) representere tilfellene hvor vi aksepterer å ha feil. 

```{r}
#| echo: false
#| message: FALSE
#| warning: FALSE

set.seed(1)
sample <- rnorm(10,3485,587) 

```


Vi trekker et utvalg med størrelse 10 fra populasjonen av registrerte fødselvekter i Norge 2022. Tallene er:

```{r}
#| echo: false
#| message: FALSE
#| warning: FALSE


library(gt)

data.frame(Vekt = round(sample, 0)) %>%
  gt() %>%
  tab_header(title = md("F&#248;dselsvekter i Norge 2022") )
```




Gjennomsnittet er `r round(mean(sample),0)` og standardavviket er `r round(sd(sample),0)`. Vi kan bruke disse verdiene til å beregne konfidensintervallet.

$$3563 \pm 1.96 \times \frac{485}{\sqrt{10}}$$
hvilket gir et intervall fra `r round(round(mean(sample),0) -  1.96 * (round(sd(sample),0)/sqrt(10)),0)`  til `r round(round(mean(sample),0) +  1.96 * (round(sd(sample),0)/sqrt(10)),0)` gram.

I tekst kan vi sammenfatte våre beregninger som:

> Gjennomsnittet av fødselvektene i Norge 2022 er estimert til `r round(mean(sample),0)` gram med et 95% konfidensintervall på [`r round(round(mean(sample),0) -  1.96 * (round(sd(sample),0)/sqrt(10)),0)`, `r round(round(mean(sample),0) +  1.96 * (round(sd(sample),0)/sqrt(10)),0)`] gram.

### *t*-fordelingen

Når vi bruker små utvalg er det bedre å bruke en *t*-fordelning når vi lager konfidensintervaller. En *t*-fordeling er en familie av fordelinger som likt normalfordelingen er symmetriske med tyngdepunkt ved sentrum. Formen på fordelingen bestemmes av antallet frihetsgrader, noe som i sin tur bestemmes av antallet observasjoner. Når antall frihetsgrader er lavt vil fordelingen være bredere og ha mer masse lengre ut fra sentrum. Når antallet frihetsgrader øker vil fordelingen nærme seg en normalfordeling (se @fig-konfidensintervall). Når vi beregner et konfidensintervall for et gjennomsnitt bruker vi $n-1$ frihetsgrader. I eksemplet med 10 observasjoner vil vi bruke en *t*-fordeling med 9 frihetsgrader.

Det at vi fanger inn mer av fordelingen lengre ut fra sentrum gjør at vi kan være mer sikre på at vi unngår å lure oss selve hva gjelder populasjonsparameteren. Hvis vi definerer feilraten som antallet 95% konfidensintervaller som ikke fanger inn populasjonsparameteren, vil vi ved bruk av en *t*-fordeling ha en feilrate som ikke overstiger 5% ved repeterte forsøk, 95% av konfidensintervallene vil faktisk fange populasjonsparameteren. Normalfordelingen og små utvalg vil derimot gi oss 95% konfidensintervall som ikke holder hva de lover, en lavere andel enn 95% vil inneholde populasjonsparameteren. I @fig-konfidensintervall C har viser vi resultatet av 50 simulerte utvalg fra fødselsvekt-dataene. Over hvert panel i figuren angis feilraten fra 2000 simuleringer. Når vi har små utvalg (n = 10) vil feilraten være større når vi bruker normalfordelingen som grunn for konfidensintervallene.

```{r}
#| echo: false
#| message: FALSE
#| warning: FALSE
#| fig-width: 6
#| fig-height: 8
#| label: fig-konfidensintervall
#| fig-cap: !expr 'paste("(A) En normalfordeling skiller seg fra en t-fordeling ved at formen ikke kan påvirkes. t-fordelingen har en ekstra parameter frihetsgrader (degrees of freedom, df) som bestemmer formen på kurven, når df nermer seg 0 faller mer av massen i fordelingen lengre ut fra sentrum. Når df > 30 ligner t-fordelingen på en normalfordeling. Vi betsemmer antallet frihetsgrader basert på antall observasjoner i dataene. (B) Et konfidensintervall basert på en t-fordeling (df=9) for observert data, et 95% konfidenintervall strekker seg &pm; ",round(qt(0.975, df=9),2)," standardfeil ut fra gjennomsnittet. (C) Et konfidensintervall for en t-fordeling er bredere enn for en normalfordeling og når antallet frihetsgrader (antallet observasjoner) er litet vil dette hjelpe oss å opprettholde feilraten, antallet konfidensintervall som ikke inneholder den faktiske populasjonsparameteren. Et antall intervall i figuren finner ikke populasjonsparameteren, feilraten er angitt over hvert panel og intervaller er markert i figuren")'



# plot a normal distribution using ggplot2

p1 <- data.frame(x = c(-5, 5)) %>%
  ggplot(aes(x)) + 
  stat_function(fun = dnorm, args = list()) +
  stat_function(fun = dt, args = list(
                                      df = 30), 
                color = "orchid") +
    stat_function(fun = dt, args = list(
                                      df = 9), 
                color = "blue") +
    stat_function(fun = dt, args = list(
                                      df = 2), 
                color = "orange") +
  theme_classic() + 
  
  annotate("text", 
           x = -4.9, 
           y = c(0.35,
                 0.3,
                 0.25,
                 0.20),
           size = 4,
           hjust = 0,
           label = c("Normal", 
                     "t, df = 30", 
                     "t, df = 9",
                     "t, df = 2"), 
                     color = c("black", "orchid", 
                               "blue", "orange")) +
  
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(), 
        axis.line.y = element_blank(), 
        axis.title.x = element_blank()) +
  labs(title = "Normal og t-fordelning",
       subtitle = " ",
       x = "Value") 


## Shade are under a t distribution

# Return dt(x) for 0 < x < 2, and NA for all other x

# example data

samp <- rnorm(10)

samp <- data.frame(samp = (samp - mean(samp))/sd(samp))


dt_limit <- function(x) {
    y <- dt(x, df = 10)
    y[x < -qt(0.975, df = 9)  |  x > qt(0.975, df = 9)] <- NA
    return(y)
}

# ggplot() with dummy data
p2 <- ggplot(data.frame(x = c(-5, 5)), aes(x = x)) +
  stat_function(fun = dt_limit, geom = "area", fill = "blue", alpha = 0.2) +
  stat_function(fun = dt, 
                args = list(df = 9), color = "blue") + 
  theme_classic() +
    theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(), 
        axis.line.y = element_blank(),
              axis.title.x = element_blank()) +
  labs(title = "t-fordelning",
  subtitle= "df = 10, 95% av area under kurven",
       x = "Value") +
  
  geom_point(data = samp, aes(x = samp, y = 0), 
             size = 2, 
             shape = 20,
             color = "steelblue") +

  annotate("segment", 
           x = -qt(0.975, df = 9), xend = qt(0.975, df = 9), y = 0.03, yend = 0.03, 
           color = "black") +
    annotate("point", 
           x = 0, y = 0.03, shape = 21,size = 4, fill = "steelblue") 




## Calculate confidence intervals using t and z distributions
## and compare them
set.seed(101)
N <- 2000

results10 <- data.frame(z_lwr = numeric(N), 
                      z_upr = numeric(N),
                      t_lwr = numeric(N),
                      t_upr = numeric(N), 
                      mean = numeric(N))

results50 <- data.frame(z_lwr = numeric(N), 
                      z_upr = numeric(N),
                      t_lwr = numeric(N),
                      t_upr = numeric(N), 
                      mean = numeric(N))


for(i in 1:N) {
  

  sample <- rnorm(10,3485,587) 
  mean <- mean(sample)
  sd <- sd(sample)
  n <- length(sample)
  z <- qnorm(0.975)
  t <- qt(0.975, df = n-1)
  
  results10[i,1] <- mean - z * sd/sqrt(n)
  results10[i,2] <- mean + z * sd/sqrt(n)
  results10[i,3] <- mean - t * sd/sqrt(n)
  results10[i,4] <- mean + t * sd/sqrt(n)
  results10[i,5] <- mean 
  results10$n <- n
  
  sample <- rnorm(50,3485,587) 
  mean <- mean(sample)
  sd <- sd(sample)
  n <- length(sample)
  z <- qnorm(0.975)
  t <- qt(0.975, df = n-1)
  
  results50[i,1] <- mean - z * sd/sqrt(n)
  results50[i,2] <- mean + z * sd/sqrt(n)
  results50[i,3] <- mean - t * sd/sqrt(n)
  results50[i,4] <- mean + t * sd/sqrt(n)
  results50[i,5] <- mean 
  results50$n <- n 
  
  }

  
errorrates <- bind_rows(results10, results50) %>%
  mutate(z_includes = ifelse(3485 > z_lwr & 3485 < z_upr, 1, 0),
         t_includes = ifelse(3485 > t_lwr & 3485 < t_upr, 1, 0)) %>%
  reframe(.by = n, 
            z_includes = round(100 * (1 - sum(z_includes)/N),1),
            t_includes = round(100 * (1 - sum(t_includes)/N),1)) 


p3 <- bind_rows(results10, results50) %>%
  group_by(n) %>%
  slice_sample(n = 50) %>%
  mutate(int = row_number()) %>%
  pivot_longer(cols = c(z_lwr, z_upr, t_lwr, t_upr), 
               names_to = "interval", 
               values_to = "val") %>%
  separate(interval, into = c("type", "side"), sep = "_") %>%
  pivot_wider(names_from = side, values_from = val) %>%
  ungroup() %>%
  mutate(includes = ifelse(3485 > lwr & 3485 < upr, "in", "out"),
        error_rate = if_else(type == "z" & n == 10, errorrates[1,2],
                             if_else(type == "z" & n == 50,errorrates[2,2],
                                     if_else(type == "t" & n == 10, errorrates[1,3],
                                             errorrates[2,3]))),
         type = if_else(type == "z", "Normal", "T"),

         n = paste("n =", n, ", feilrate = ", error_rate, "%") ) %>%
        
  
  
  ggplot(aes(x = int, y = mean, 
             color = type, alpha = includes)) +
  
    geom_hline(yintercept = 3485, linetype = 2) +
  
  geom_errorbar(aes(ymin = lwr, ymax = upr), 
                position = position_dodge(width = 0.5), 
                width = 0) +
  
  scale_alpha_manual(values = c(0.2,1), ## exclude from legend
                     guide = "none") +
  scale_color_manual(values = c("orchid", "steelblue")) +
  
  geom_point(position = position_dodge(width = 0.5)) + 
  facet_wrap(~ n, ncol = 1) +
  theme_classic() + 
  theme(strip.background = element_rect(color = "white"), 
        legend.position = "bottom") + 
  labs(x = "Utvalg", 
       y = "Gjennomsnitt (gram) 95% konfidensintervall", 
       color = "Sannsynlighetsfordeling")
  
  
plot_grid(NULL, 
          plot_grid(p1, p2, ncol = 2, rel_widths = c(1,1)), 
          p3, nrow = 3, rel_heights = c(0.05,0.4,1)) +
  # add labels
  draw_plot_label(label = c("A", "B", "C"), 
                  x = c(0.01, 0.48, 0.01),
                  y = c(1, 1, 0.7)) 

```

I din mer avanserte statistikkbok finner du kanskje følgende formel for et konfidensintervall for gjennomsnittet basert på t-fordelingen:

$$\bar{x} \pm t_{\text{df}=9,\alpha/2} \times \frac{s}{\sqrt{n}}$$
$t_{\text{df}=9,\alpha/2}$ er faktoren som angir hvor mange standardfeil vi må bevege oss fra gjennomsnittet for å finne konfidensintervallets grenser, gitt at vi bestemmer oss for $\alpha$. For et 95% konfidensintervall med antall frihetsgrader satt til 10 er faktoren `r round(qt(0.975, df=9), 3)`.

Konfidensintervaller er altså en måte å uttrykke usikkerhet på, men det er viktig å huske hva de beskriver. Et 95% konfidensintervall sier at ved repeterte utvalg/eksperimenter vil 95% av konfidensintervallene, som det observerte intervallet kommer fra, fange inn den parameter vi ønsker å estimere fra populasjonen (populasjonsparameteren). Men vi vet ikke om vårt intervall faktisk gjør det, vi kjenner bare til sannsynligheten for at vi gjør det i det lange løp.

## Hypotesetesting og p-verdier
I statistikken har vi mulighet å teste hvor kompatible våre data er med en gitt hypotese. Vi kan formulere en hypotese for kontinuerlig data gjennom å velge et tall som vi tester mot. Den frekventistiske statistikken bruker nullhypoteser og rundt denne hypotesen bygger vi opp en estimert utvalgsfordeling. Vi kan nå besvare spørsmålet: Gitt att nullhypotesen er sann, hvor sannsynlig er det at vi får et resultat så ekstremt som det vi observerer, eller enda mer ekstremt?

Denne definisjonen er dessverre ikke helt intuitiv, vi lager et eksempel under for å bedre forstå den. La oss si at vi gjennomfører et forsøk hvor vi studerer effekten av fysisk aktivitet på blodtrykk. De rekrutterte deltakerne (n=50) som i utgangpunkt har høyt blodtrykk fordeles tilfeldig (randomisert) til to grupper. Gruppe A får ingen retningslinjer for fysisk aktivitet, gruppe B får oppfølging fra en personlig trener. Etter en intervensjonsperiode tester vi blodtrykket (@fig-hypotesedata).

Fra studien er det mulig å formulere to hypoteser, en nullhypotese ($\text{H}_0$) sier at det ikke er noen forskjell mellom gruppene. Den alternative hypotesen ($\text{H}_0$) sier derimot at det er en forskjell i blodtrykk mellom gruppene etter intervensjonsperioden. Filosofiske argumenter gir at det er vanskelig å bevise en hypotese men enklere å motbevise den. I statistikken prøver vi derfor vanligvis å motbevise (falsifisere) nullhypotesen, og vi sier at vi *tester mot den*. Vi setter opp testet sånn at om testresultatet er tilstrekkelig ekstremt gitt at nullhypotesen er sann så avkrefter vi den, eller finner den mindre trolig enn en alternative hypotese.



$$\text{H}_0: \mu_1 = \mu_2$$

$$\text{H}_A: \mu_1 \neq \mu_2$$

```{r}
#| echo: false
#| message: FALSE
#| warning: FALSE
#| fig-width: 6
#| fig-height: 4
#| label: fig-hypotesedata


### Create data sets of blood pressure 

set.seed(1)
A <- rnorm(25, 129, 15)
B <- rnorm(25, 124, 15)



data.frame(A, B) %>%
  pivot_longer(cols = c(A, B), 
               names_to = "Gruppe", 
               values_to = "Blodtrykk") %>%
  ggplot(aes(x = Gruppe,y = Blodtrykk, fill = Gruppe)) + 
  geom_point(shape = 21, position = position_jitter(width = 0.1)) +

  theme_classic() + 
  
    theme(legend.position = "none") +
  labs(x = "Gruppe", y = "Systolisk blodtrykk (mmHg)") 


```

Datane vi samlet inn forteller at forskjellen mellom gruppene i systolisk blodtrykk etter intervensjonen er `r round(mean(A) - mean(B), 1)` mmHg. Hvis nullhypotesen er sann, hvor usannsynlig er det observerte resultatet? For å etterligne en nullhypotese skaper vi en kunstig utvalgsfordeling under nullhypotesen. Denne fordelingen lager vi gjennom å gi gruppetilhørighet til våre observasjoner helt tilfeldig, 10 000 ganger. Vi trekker altså tilfeldig deltakere fra utvalget og plasserer de i to grupper. Hver gang beregner vi et gjennomsnitt mellom gruppene som nå er en blanding av individer fra de faktiske intervensjonsgruppene. Gjennomsnittene samler vi opp og så beregner vi hvor mange gjennomsnitt som er så ekstreme eller enda mer ekstreme sammenlignet med det observerte gjennomsnittet fra intervensjonen. Vi sammenligner altså resultatet fra intervensjonen med gjennomsnitt som er mulige hvis tilfeldigheter og ikke intervensjonen bestemmer verdiene som vi har observert. Denne teknikken kalles for permutasjonstest og resultatet finner vi i @fig-permutasjonstest.


```{r}
#| echo: false
#| message: false
#| warning: false
#| cache: true
#| fig-width: 6
#| fig-height: 4
#| label: fig-permutasjonstest


N <- 10000


diffs <- vector()
for(i in 1:N) {
  
 dat <-  data.frame(val = c(A, B)) %>%
    mutate(group = sample(rep(c("a", "b"), each = 25), 50, replace = FALSE)) 
  
  m <- lm(val ~ group, data = dat)
  diffs[i] <- coef(m)[2]
  
}


## Number of more extreme values

oneside <- sum(diffs > mean(A) - mean(B), na.rm = TRUE) / N

twoside <- sum(abs(diffs) > abs(mean(A) - mean(B)), na.rm = TRUE) / N



data.frame(diffs) %>%
  ggplot(aes(x = diffs)) + 
  
  geom_histogram(fill = "lightblue", 
                 color = "gray23") + 
  
  geom_vline(xintercept = mean(A) - mean(B), color = "red") + 
  annotate("text", x = mean(A) - mean(B) - 1, y = 250, label = "Observert forskjell", color = "red", 
           angle =90) +
  
  
  theme_classic() + 
  labs(x = "Forskjell i gjennomsnitt", y = "Antall permutasjoner")




```




Det viser seg at bare `r oneside`% av gjennomsnittene er mer ekstreme enn det gjennomsnitt vi fikk fra intervensjonen. Er dette nok for å forkaste nullhypotesen? Hvis vi setter grensen på 5% kan vi si at vi i det lange løp (flere repeterte studier med den samme statistiske tilnærmingen) vil forkaste nullhypotesen, til tross for at den er sann i 5% av tilfellene. Å gjøre denne feilen kalles for et Type-1 feil. 

`r twoside` 


## Type 2 feil, statistisk styrke og utvalgsstørrelser
Så langt vet vi at vi kan gjøre en type 1 feil ved å forkaste nullhypotesen til tross for at den er riktig. Den frekventisktiske statistikken er opptatt av å kontrollere denne feilen, vi ønsker statistiske tester som har en gitt feil-rate i det lange løp (over flere lignende, uavhengige studier). I tillegg til type 1 feil kan vi også gjøre en annen feil ved å ikke forkaste nullhypotesen til tross for at en alternativ hypotese er sann. Denne feilen kalles for type-2 feil og den krever litt mer arbeid fra oss som skal analysere dataene. Vi kan sette opp de to typene feil i en tabell som under.


|Nullhypotesen er... |Sann |Falsk|
| --- | --- |---|
|**Forkasted** |<span style="color:red">Type-1 feil</span>|Riktig avgjørelse|
|**Ikke forkasted**|Riktig avgjørelse|<span style="color:red">Type-2 feil</span>|

I et scenario med to grupper som vi ønsker å sammenligne har vi formulert en nullhypotese som sier at det ikke finnes en forskjell mellom gruppene på populasjonsnivå. Husk at med statistisk inferens ønsker å si noe om data som vi ikke har observert (populasjonen) basert på data som vi har observert (utvalget). Før vi innhenter data formulerer vi også en alternativ hypotese. Vi lager denne alternative hypotesen basert på noen fakta vi allerede har om problemet. La oss ta fysisk aktivitet og blodtrykk som eksempel igjen.

En forandring i systolisk blodtrykk etter en behandling så stor som 5-10 mmHg kan sies være den minste forskjellen som er klinisk betydningsfull. Her kan vi argumentere for at en senkning av blodtrykk med 5-10 mmHg kreves for at en individ skal oppleve helsefordeler med behandlingen. Vi bruker 10 mmHg for å etablere en alternativ hypotese til nullhypotesen. Vi ønsker nå en statistisk test som oppdager denne forskjellen mellom to grupper, om den faktisk finnes. Evnen til en statistisk test å forkaste nullhypotesen til fordel for den alternative hypotesen kalles for statistisk styrke. Den statistiske styrken defineres som en minus den forventede raten med hvilken vi gjør type 2 feil ($1-\beta$). 

I populasjonen som vi ønsker å undersøke er den gjennomsnittlige systoliske blotrykken 135 mmHg med en standardavvik på 20 mmHg. Vår alternative hypotese er at fysisk aktivitet senker blodtrykket med 10 mmHg. Disse tallene kan vi bruke for å beregne hvilken utvalgsstørrelse som gir en gitt statistisk styrke. Som et første steg trenger vi en standardisert effektstørrelse ($d$), denne er
$$d = \frac{H_a}{SD} = \frac{10}{20} = 0.5$$ En standardisert effektstørrelse er en måte å beskrive en effekt i termer av variasjonen. Hvor stor er effekten i forhold til den gjennomsnittlige variasjonen i populasjonen? Neste steg blir å bestemme hvilken statistisk styrke og hvor stor risiko for type 1 feil vi ønsker i testen. Her kan vi bruke en argumentasjon som går ut på at en type 1 feil er alvorligere enn type 2 feil. La oss si 4 ganger alvorligere, hvis vi ikke ønsker å gjøre en type 1 feil mer enn i 5% av repeterte studier kan vi leve med risikoen å gjøre en type 2 feil som er $5\% \times 4 = 20\%$.

For å til slutt beregne en utvalgsstørrelse har vi å følgende parameterer
| | |
|--- | ---|
|Effektstørrelse | 0.5|
|Risiko for type 1 feil ($\alpha$)| 5%|
|Risiko for type 2 feil ($\beta$)| 20%|
|Statistisk styrke ($1-\beta$)| 0.8|

Vi ønsker å gjøre en sammenligning mellom to uavhengige grupper og vi tillater at nullhypotesen kan forkastes i to retninger da trening i teorien kan gi lavere og høyere blodtrykk. Dette spesifiserer den statistiske testen som skal brukes (tosidig t-test med uavhengige grupper). Med denne informasjonen kan vi bruke Jamovi for å beregne utvalgsstørrelse.

### Mer om effektstørrelser
Tidligere har vi snakket om sammenhenger mellom variabler og hvordan vi kan måle disse. I de fall vi ønsker å sammenligne to grupper undersøker vi om det finnes en *sammenheng mellom gruppe og den avhengige variabelen*. Det kan være enklere å si det sånn at vi ønsker å undersøke forskjellen mellom gruppene. En effekt i denne sammenhengen kan beskrives på flere måter, som en absolutt forskjell (eks. 10 mmHg), som en forskjell relativ till en utgangsverdi (eks. $10/135 = 0.74 = 7.4\%$) eller som en forskjell standardisert till standardavviket i målevariabelen ($10/20 = 0.5$). Den standardiserte effektstørrelsen kalles også for Cohen's $d$ etter en kjent statistiker og psykolog.

En standardisert effektstørrelse kan sammenlignes mellom studier og målevariabler. Vanligvis (etter beskrivning av Cohen[@cohenStatisticalPowerAnalysis2013]) beskriver man en effektstørrelse som liten hvis $d = 0.2$, medium ved $d=0.5$ og stor ved $d=0.8$. En standardisert effektstørrelse kan også konverteres til forskjellige skaler. En medium Cohen's $d$ (0.5) kan for eksempel transformeres til en korrelasjonskoeffisient $r= 0.243$. Dette gjør at standardiserte effektstørrelser blir brukt i meta-analyser hvor flere studier settes sammen for å undersøke et gitt fenomen.

I sammenligning av to gjennomsnitt har effektstørrelsen en sammenheng med p-verdien som er avhengig av utvalgsstørrelse. Vid en gitt utvalgsstørrelse synker p-verdien når effektstørrelsen blir større. 

## Statistiske tester, studiedesign og utvalg
I flere eksempler har vi brukt data fra observasjonsstudier. I disse studiene samler vi inn data fra et utvalg og undersøker sammenhenger mellom variabler. Fra disse studiene er det typisk vanskelig å trekke konklusjoner om hva som ligger bak en observert effekt. Resultater fra observasjonsstudier kan brukes til å bedre forstå kausale sammenhenger, men dette krever en teoretisk modell og at vi måler andre variabler som kan tenkes influere sammenhenger mellom to variabler som vi er interesserte i. Til sammen kan disse brukes for å fastslå årsakssammenhenger. 

I et eksperiment trenger vi ikke å lage de samme teoretiske og statistiske modellene for å forstå sammenhenger, eller for eksempel, forskjeller mellom to grupper. Det som kreves er at faktorer som kan influere resultatene, kjente og ukjente, blir tilfeldig fordelt mellom de eksperimentelle gruppene/behandlingene. På den måten kan vi si at effekten av intervensjonen er den effekt som skiller gruppene åt og ikke noen annen faktor som blir introdusert i eksperimentet. Da en tilfeldig prosess ligger til grunn for inndeling av deltakere i forskjellige grupper er også resultatene til større grad generaliserbare til nye individer fra den samme populasjonen. I et eksperiment ønsker vi derfor å kontrollere mulige faktorer ved å tilfeldig allokere forsøkspersoner til eksperimentelle grupper, også kalt randomisering.

Det finnes flere ulike varianter av randomisering som kan tilpasses forskjellige studiedesigner. Målet er å gi for eksempel deltakere like stor sannsynlighet for å deles inn i forskjellige grupper. Til tross for at vi bruker randomisering kan tilfeldigheter ha stor betydelse for resultatene i eksperimentelle studier. Dette særlig i små studier hvor tilfeldig variasjon i utvalget kan påvirke resultatene. Vi kan forstå dette ved å tenke på en studie hvor seks deltakere randomiseres til to grupper. I populasjonen finnes en faktor som har stor betydelse for resultatene i studien hos en av seks personer. I vår studie trekker vi et utvalg som direkte avspeiler populasjonen, en deltaker er bærer av den betydningsfulle faktoren. Til tross for randomisering så finnes ingen annen måte å fordele individet som har denne faktoren, og de som ikke har den på en ubalansert måte. En gruppe vil få denne faktoren. Hvis vi rekrutterer et større utvalg vil randomiseringen balansere faktoren mellom gruppene.

Effekten av små studier kan ha stor betydelse for hvordan vi toker resultater fra studier.  Det viser seg at om vi simulerer studier med få antall deltakere fra populasjoner med kjente effektstørrelser vil små studier (gruppestørrelser 5-25 individer) som regel gi oss flere estimat på effekter som er utrolige. Her finnes en fare i å tolke en stor effektstørrelse som betydningsfull når p-verdien gir beskjed om at vi bør være skeptiske. P-verdien (og t-verdien) tar høyde for en liten utvalgsstørrelse. Når vi har få deltakere i en studie vil halene på en t-fordeling inneholde mer masse. Ved en lignende effektstørrelse vil vi derfor beregne en mer konservativ (skeptisk) p-verdi. Når vi ikke har en effekt i populasjonen og simulerer studier fra disse beskytter p-verdien fra å forkaste nullhypotesen, vi vil bare ha feil i 5% av repeterte studier når vi setter dette som grensen for testene. Med få deltakere vil vi ikke finne effekten som finnes i populasjonen. Dette betyr at p-verdien ikke er avhengig av antall forsøkspersoner i en studie, med den statistiske styrken er det.







