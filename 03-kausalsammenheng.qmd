---
execute: 
  eval: true
  echo: false
  warning: false
  message: false
editor_options: 
  chunk_output_type: console
---

# Fra sammenheng til kausalitet

Samtidig som vi vet at noen sammenhenger er spuriøse[^spur] vet vi også at noen ting påvirker andre ting, det finnes kausalitet[^kausal]. I et forsøk undersøker vi hvordan en ny medisin påvirker blodtrykket. En gruppe forsøkdeltakere blir tilfeldig inndelt i to grupper. Deltakere i den ene gruppen får den nye medisinen og deltakere i den andre gruppen får placebo. Inndeling av deltakere i gruppene er skjult for deltakere og forskere. I etterkant av intervensjonen måler vi blodtrykk og kan konstatere at deltakere som fått medisinen har lavere blodtrykk sammenlignet med placebo-gruppen. Forsøket inneholder noen komponenter som gjør at vi kan si at det finnes en kausal sammenheng mellom det å ta medisinen og det å få lavere blodtrykk. Hvis vi hadde muligheten å forandre på en variabel for deretter å måle utfallet i en annen variabel, under kontrollerte forhold så kan vi si at det finnes (eller ikke) en kausal sammenheng. Det å forandre en variabel (f.eks. konsentrasjonen av et medikament i blodet) kan kalles for å gjøre en intervensjon.  

[^spur]: Spuriøs sammenheng er en sammenheng mellom to variabler som ikke har en kausal sammenheng.

[^kausal]: Kausalitet er en sammenheng mellom to variabler hvor en variabel påvirker en annen.

I mange sammenhenger har vi ikke mulighet å forandre variabler ved å lage intervensjoner. Det kan for eksempel finnes etiske eller praktiske årsaker til dette. Men vi har fortsatt mulighet til å undersøke kausale sammenhenger. Som i eksemplet med medisin for lavere blodtrykk over så krever det noen antagelser. I et forsøk hvor vi intervenerer kan antagelser inkludere at forsøkdeltakere blir tilfeldig tildelt en gruppe og at forskere ikke vet hvilken pasient eller forsøkdeltakere som får den aktive behandlingen eller medisinen. Hvis disse antakelsene er sanne så kan vi med stor sikkerhet si at medisinen påvirket blodtrykket. I en forskningstudie hvor vi ikke har mulighet å intervenere har vi fortsatt mulighet å «kontrollere» for variabler som kan påvirke sammenhengen mellom to variabler som vi er interessert i. Vi kan identifisere variabler som vi bør kontrollere for ved hjelp av grafiske modeller. Disse modellene kan også gi innsikt i når vi ikke kan si at en sammenheng er årsaksbestemt.

Over har vi beskrevet to typer av studiedesign, en eksperimentell studie og en observasjonsstudie. I en eksperimentell studie gjennomfører vi en eller flere intervensjoner som forandrer variabler og vi kan derved estimere effekten av disse variablene på avhengige variabler. I en observasjonsstudie har vi ikke denne muligheten, her estimerer sammenhenger mellom variabler ved hjelp og trekker slutninger om kausalitet basert på antagelser om hvordan variabler henger sammen. I begge typer av studier kan vi si noe om kausale sammenhenger.

::: {.column-margin}

 &#x1F4F9; Forelesning: [Intro til kausal inferens](https://inn.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=26f2e4ef-c766-450f-af3a-b14800bf9fe0){target="_blank"}.

:::


## Eksperiment og kvasieksperiment 

Et eksperiment kan brukes til å sammenligne intervensjoner. Vi sammenligner intervensjonene i en definert gruppe. Denne gruppen, eller populasjonen, kan som et eksempel være idrettsutøvere, og intervensjonene kan være to forskjellige treningsprogrammer hvor et program er et nytt program (N) og det andre er hva man vanligvis bruker, en slags kontrollprogram (K). Vi ønsker med vårt eksperiment å si noe om effekten av N på en bestemt variabel i gruppen idrettsutøvere. Vi rekrutterer en gruppe idrettsutøvere og deler inn dem i to undergrupper, N og K. 

::: {.column-margin}

 &#x1F4F9; Forelesning: [Spuriøse sammenhenger](https://inn.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=84330ac4-df0a-480d-bd46-b14800c2703d){target="_blank"}.

:::


For å gjøre sammenligningen bestemmer vi et utfall (avhengig variabel), i eksemplet passer det fint å måle løpehastighet i en 3000-m test. Vi lar utøverne løpe testen i forkant av studien, ved tid 1 ($t_1$), og etter studien, ved tid 2 ($t_2$). Vi kan nå beregne en forandringskår ($\delta$). Hvor mye forandret seg hvert enkelt individ fra $t_1$ til $t_2$? 

$$\Delta = t_2 – t_1$$ 

I neste steg kan vi beregne effekten av N, det nye treningsprogrammet. For å beregne denne så trekker vi ifra forandringen i K ($\Delta_K$) fra effekten av N ($\Delta_N$), denne beregning gir oss den gjennomsnittlige intervensjonseffekten (GIE) av å gjennomføre N, sammenlignet med et kontrollprogram (K). 

$$ \Delta_N - \Delta_K = \text{GIE}$$ 

For å si at den estimerte GIE er den kausale effekten av å gjennomføre N kreves noen grep og antagelser. Når vi delte inn deltakere i studien så må vi ta grep for å gi hvert deltakere samme sannsynlighet å ende opp i hver gruppe. Vi sikkerstille dette ved å randomisere forsøket. I et randomisert forsøk bruker man vanligvis et dataprogram som tilfeldig tildeler gruppetilhørighet til hvert individ. Inndelingen av gruppene påvirkes ikke av forskerne, deltakerne eller andre faktorer som samtidig kan påvirke resultatene. Dette er en aspekt av forsøket som gjør at vi kan kalle det for et eksperiment. 

Et nærbeslektet design er en kvasieksperimentell studie. I en slik studie har noe ytterligere påvirket gruppeinndelingen og dermed påvirket effekten som er utfallet av studien. Et eksempel på en effekt som kan påvirke resultatene i en studie hvor en kvasieksperimentell design brukes er om inndelingen i grupper gir en overvekt av dårlig trente utøvere i den ene gruppen grunnet deltakernes preferanser. En dårlig trent individ kan forventes svare bedre på trening og hvis mange av disse er samlet i en gruppe forsvinner eller forsterkes effekten av intervensjonen. Vi kan forstå denne situasjonen enda bedre ved hjelp av en figur (@fig-eksperimentkvasi).

```{r}
#| label: fig-eksperimentkvasi
#| fig-cap: En ekseprimentell studie (A) gjennomfører gruppeindelning (*G*) ved hjelp av randomisering (*R*). Gruppeinndelingen er den ende effekten som påvirker forandring i prestasjon (*P*). I et kvasiekperimentellt design påvirker randomisering (*R*) og en uobservert variabel (*K*) gruppeinndelingen. *K* påvirker også forandringen i prestasjon noe som gjør at vi ikke med sikkerhet kan si noe om effekten av *G* på *P*.
#| fig-width: 6
#| fig-height: 2

library(tidyverse); library(ggdag)

## Experiment
dag_coords <-
  tibble(name = c("R", "G", "P"),
         x    = c(1, 2, 3),
         y    = c(1, 1, 1))

# save our DAG
dag <-
  dagify(P ~ G,
         G ~ R,
         coords = dag_coords)

# plot 
experiment <- dag %>%
  tidy_dagitty() %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(alpha = 1, size = 12, color = "lightpink") +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +
  theme(plot.background = element_rect(fill = "lightpink")) 

## qasi-experiment
dag_coords <-
  tibble(name = c("R", "G", "P", "K"),
         x    = c(1, 2, 3, 2.5),
         y    = c(1, 1, 1, 2))

# save our DAG
dag <-
  dagify(P ~ G + K,
         G ~ R + K,
         
         coords = dag_coords)

# plot 
quasi <- dag %>%
  tidy_dagitty() %>%
  mutate(circ = if_else(name == "K", "c", "n"), 
         lin = if_else(name == "R", "n", "c")) %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(aes(color = circ), alpha = 1, size = 12, shape = 21) +
  scale_color_manual(values = c("black", "lightblue")) +
  geom_dag_text(color = "black") +
  geom_dag_edges(edge_color = "black") + 
  theme_dag() + 
  scale_y_continuous(limits = c(0.9, 2.2)) +
  theme(legend.position = "none", 
        plot.background = element_rect(fill = "lightblue"))  


library(cowplot)


plot_grid(experiment, quasi, labels = c("A", "B"))



```

Det randomiserte forsøket (A i figuren over) inneholder ikke noen mulige variabler som kan påvirke gruppeinndeling annet enn den tilfeldige tildelingen av gruppetilhørighet (randomisering, *R*). I det kvasieksperimentelle designet (B i figuren over) påvirker den uobserverte variabelen *K* gruppetilhørighet, da deltakere får mulighet å velge gruppe selve. Variabelen *K* påvirker også forandring i prestasjon (*P*) ved at deltakere velger gruppe basert på noen karakteristikk, som for eksempel hvor trent de er.

## Grafiske modeller for kausal analyse

::: {.column-margin}

 &#x1F4F9; Forelesning: [Kausale modeller](https://inn.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=e17be367-ed01-45a9-97a1-b14800c3de1b){target="_blank"}.

:::

I eksemplet over bruker vi en grafisk modell til å beskrive hvordan forskjellige variabler henger sammen. Denne typen av modell har navnet *Directed Acyclic Graph* (*DAG*, "rettet asyklisk graf" på norsk), noe som beskriver modellens egenskaper. Modellen viser retningen av en "effekt" mellom to variabler (directed), og en variabel kan ikke påvirke seg selv, modellen er ikke syklisk (acyclic). Vi kan tenke på hele grafen som forhold mellom variabler ved et bestemt tidspunkt. 

Den grafiske modellen inneholder noder (nodes), disse bruker vi for å plassere inn variabler, og kanter (edges) som vi bruker for å beskrive retning på effekter, hvordan en variabel påvirker en annen. I figuren over (@fig-eksperimentkvasi) sier vi at *G* (gruppetilhørighet) er en variabel (nod) som påvirker *P* direkte ved en kobling mellom de to.

Denne typen av grafisk modell har noen begrensninger, den forteller for eksempel ikke om hvordan variabler påvirker hverandre. En effekt, som beskrevet i en DAG, ser lik ut når variablene er kategoriske og kontinuerlige. En DAG beskriver ikke heller styrken i en sammenheng. For eksempel er det å kjøpe en lodd $L$ kausalt sammenkoblet [med å vinne en million](https://www.vg.no/nyheter/innenriks/i/bgBjae/mann-31-pantet-en-boks-og-vant-en-million-i-pantelotteriet) $V$ ($L \rightarrow V$), men sammenhenger er ikke så sterk. Så vad kan vi bruke en DAG til?

En DAG gir oss muligheten til å koble sammen en statistisk modell, for eksempel en regresjonsmodell, med en vitenskapelig modell. Den vitenskaplige modellen, illustrert gjennom en DAG, viser hvordan vi anser at variabler henger sammen og hvordan vi kan tolke, eller forandre den statistiske modellen for å la den beskrive kausale effekter. Den vitenskaplige modellen bygger på antagelser. Når vi beskriver en kausal effekt betyr det at vi sier at den er kausal under betingelser at de antagelser vi stiller opp er sanne. Beskrevet på denne måten er det tydelig at vi ikke kan finne kausale sammenhenger hvis vi bare analyserer dataene, vi trenger en vitenskaplig modell i tillegg [@pearl_seven_2019].

::: {.column-margin}
Pearl [-@pearl_book_2018; -@pearl_seven_2019] er en sentral bidragsyter til feltet kausal inferens.  
:::

## Gaffel, rør, collider og etterkommer

Når vi bygger, eller leser en DAG kan vi identifisere følgende sammenhenger mellom variabler, en gaffel, et rør, en collider og en etterkommer (@fig-dags). I en "gaffel" påvirker en variabel to andre variabler. Denne strukturen så vi i eksemplet over hvor en tredje variabel ble introdusert i eksperimentet ved at forsøkdeltakere fikk mulighet å velge gruppe selv. Denne tredje variabelen introduserer noe som kalles for en "konfunder" effekt[^dagnorsk], en variabel som påvirker både en mulig kausal variabel og variabelen som den i sin tur påvirker. 

[^dagnorsk]: Les mer i @roislien_trekantdrama_2021 som gir oss norsk oversettelse av de engelske begrepene.

I et "rør" påvirker en variabel, x, en annen variabel, y, gjennom en tredje variabel z (@fig-dags). Denne strukturen er en del i en struktur som beskrives i [@roislien_trekantdrama_2021] som en mediatoreffekt. Som vi skal se under kan vi også identifisere røret i et eksperiment hvor effekten av en intervensjon på en variabel påvirker en annen variabel gjennom en tredje variabel.

En collider er en variabel som har to "foreldrer". To variabler bidrar til å påvirke en tredje variabel. En norsk benevning av collider finnes ikke så vi låner det engelske begrepet som antyder at noe om en kollisjon. To effekter kolliderer i en tredje variabel. Under vil vi se hvordan en collider kan bidra til å skape en spuriøs sammenheng mellom to variabler som ikke er kausalt sammenkoblet.

Til sist kan vi identifisere en etterkommer (@fig-dags). En etterkommer er en variabel som påvirkes av en annen variabel. I en DAG kan vi identifisere en etterkommer ved at en variabel har en foreldervariabel. En etterkommer er et speilbilde av forelderen, og vi kan si at variabelen er en konsekvens av forelderen.


```{r}
#| label: fig-dags
#| fig-cap: "Fire forhold mellom variabler i en DAG. I en gaffel påvirkes to uavhengige variabler av den samme variabelen. I et rør er to variabler sammenkoblet ved hjelp av en tredje variabel, all effekt går gjennom denne variabelen. I en collider kolliderer effektene fra to uavhengige variabler. En etterkommer (D) påvirkes av en variabel og er dermed et speilbilde av denne variabelen."
#| fig-width: 5
#| fig-height: 5



library(ggtext)

## FORK
fork_coords <-
  tibble(name = c("X", "Y", "Z"),
         x    = c(1, 3, 2),
         y    = c(1, 1, 2))

# save our DAG
fork_dag <-
  dagify(Y ~ Z,
         X ~ Z,
         coords = fork_coords)

## Pipe
pipe_coords <-
  tibble(name = c("X", "Y", "Z"),
         x    = c(1, 3, 2),
         y    = c(2, 1, 1.5))

# save our DAG
pipe_dag <-
  dagify(Y ~ Z,
         Z ~ X,
         coords = pipe_coords)


## Collider
collider_coords <-
  tibble(name = c("X", "Y", "Z"),
         x    = c(1, 3, 2),
         y    = c(1, 1, 2))

# save our DAG
collider_dag <-
  dagify(Z ~ Y,
         Z ~ X,
         coords = collider_coords)

## Descendant
des_coords <-
  tibble(name = c("X", "Y", "Z", "D"),
         x    = c(1, 3, 2, 2),
         y    = c(1, 1, 2, 1.2))

# save our DAG
des_dag <-
  dagify(Z ~ Y,
         Z ~ X,
         D ~ Z,
         coords = des_coords)



# plot 
fork <- fork_dag %>%
  tidy_dagitty() %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(alpha = 1, size = 12, color = "white") +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +
  theme() + 
  labs(title = "Gaffel")

pipe <- pipe_dag %>%
  tidy_dagitty() %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(alpha = 1, size = 12, color = "white") +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +

  labs(title = "R&#248;r") +
    theme(plot.title = element_markdown()) 


collider <- collider_dag %>%
tidy_dagitty() %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(alpha = 1, size = 12, color = "white") +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +

  labs(title = "Collider") +
    theme(plot.title = element_markdown()) 


des <- des_dag %>%
  tidy_dagitty() %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(alpha = 1, size = 12, color = "white") +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +

  labs(title = "Etterkommer") +
    theme(plot.title = element_markdown()) 



plot_grid(fork, pipe, collider, des, ncol = 2)



```

### Konfunderte effekter

Som vi allerede konstatert over så er en konfunder (Z) en variabel som påvirker både en mulig kausal variabel (X) og variabelen som vi tror at den i sin tur påvirker (Y, se @fig-konfunder). Gaffelen som oppstår i en slik situasjon forsterker sammenhengen mellom X og Y. Når vi i en regresjonsmodell bare måler sammenhengen mellom X og Y så vil vi se en sterk sammenheng, men gjennom å "kontrollere" for konfunderen så vil vi se at sammenhengen mellom X og Y forsvinner, eller blir svakere. Konfunderen er en variabel som vi bør kontrollere for i en statistisk modell for å kunne si noe om en kausal sammenheng mellom X og Y.

```{r}
#| fig-width: 3
#| fig-height: 3
#| fig-align: "center"
#| label: fig-konfunder
#| fig-cap: "En konfunder (K) påvirker både en uavhengig variabel (X) og en avhengig variabel (Y)."


## FORK
fork_coords <-
  tibble(name = c("X", "Y", "Z"),
         x    = c(1, 3, 2),
         y    = c(1, 1, 2))

# save our DAG
fork_dag <-
  dagify(Y ~ Z,
         X ~ Z,
         Y ~ X,
         coords = fork_coords)

fork_dag %>%
  tidy_dagitty() %>%
   mutate(effect = if_else(name == "X", "dashed", "solid")) %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(alpha = 1, size = 12, color = "white") +
  geom_dag_text(color = "black") +
  geom_dag_edges(aes(edge_linetype = effect)) + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +
  theme() + 
  labs(title = "")

```

Vi kan illustrerer dette ved hjelp av en simulering. Vi lar $X$ og $Y$ være to uavhengige variabler, $Z$ er en konfunder som påvirker både X og Y. Den eneste uavhengige variabelen i dette systemet er $Z$. Her under sier vi at $Z$ er en normalfordelt variabel med gjennomsnitt 0 og standardavvik 1. $X$ er en variabel som for hvert observasjon har en verdi som er trukket fra en normalfordeling med gjennomsnitt $Z$ og standardavvik 1. $Y$ er en variabel som for hvert observasjon har en verdi som er trukket fra en normalfordeling med gjennomsnitt $Z$ og standardavvik 1. Vi kan nå se på sammenhengen mellom $X$ og $Y$ og sammenhengen mellom $X$ og $Y$ når vi kontrollerer for $Z$.

\begin{align}
Z &\sim N(0, 1) \\ 
X &\leftarrow N(Z, 1) \\ 
Y &\leftarrow N(Z,1)
\end{align}

I den første modellen bruker vi $Y$ som den avhengige variabelen og $X$ som den uavhengige variabelen. I den andre modellen bruker vi $Y$ som den avhengige variabelen og $X$ som den uavhengig variabel, men vi kontrollerer samtidig for $Z$.

\begin{align}
\text{Modell 1:} \qquad Y &= \beta_0 + \beta_1 X  \\ 
\text{Modell 2:} \qquad  Y &= \beta_0 + \beta_1 X + \beta_2 Z
\end{align}



```{r}
#| label: tbl-konfunder
#| tbl-cap: "Sammenhengen mellom Y og X estimert ved bruk av lineær regresjon. "
#| echo: false




library(gt)

set.seed(1)


z <- rnorm(1000, 0, 1)
x <- rnorm(1000, z, 1)
y <- rnorm(1000, z, 1)

m1 <- lm(y ~ x)
m2 <- lm(y ~ x + z)




bind_rows(
  data.frame(coef(summary(m1))) %>%
  select(Estimat = Estimate, Standardfeil = Std..Error) %>%
  rownames_to_column("Koeffisient") %>%
  filter(Koeffisient == "x") %>%
  mutate(Koeffisient = "&#946;<sub>1</sub>", 
         Modell = 1),
  
data.frame(coef(summary(m2))) %>%
  select(Estimat = Estimate, Standardfeil = Std..Error) %>%
  rownames_to_column("Koeffisient") %>%
  filter(Koeffisient == "x") %>%
  mutate(Koeffisient = "&#946;<sub>1</sub>", 
         Modell = 2)) %>%
  select(Modell, Koeffisient, Estimat, Standardfeil) %>%
  gt() %>%
  fmt_markdown(columns = vars(Koeffisient)) %>%
  fmt_number(columns = vars(Estimat, Standardfeil), decimals = 2)
  
```

Når vi evaluerer koeffisientene fra modellen ser vi at sammenhengen mellom $Y$ og $X$ forandres når vi inkluderer $Z$ i modellen (tbl-konfunder). I modell 1 er sammenhengen mellom variablene er sterk, vi kan lese dette som at sammenhengen tilsvarer `r round(coef(summary(m1))[2, 3], 0)` standardfeil ($\frac{Estimat}{Standardfeil}$). Når vi introduserer Z i modell 2 ser vi at sammenhengen mellom X og Y forsvinner, her er effekten mindre enn en standardfeil (`r round(coef(summary(m2))[2, 3], 1)`).

Vi kan forklare dette med at vi gjennom å kontrollere for $Z$ har målt sammenhengen mellom $X$ og $Y$ som ikke er forurenset av konfunderen. Dette er det samme som at kontrollere for $Z$, eller å "blokkere" effekten av $Z$ på $Y$. I praksis måler vi, ved hjelp av regresjonsmodellen effekten av $X$ på $Y$ på hvert nivå av $Z$.

### Konfounder, et eksempel

I en observasjonstudie undersøker vi sammenhengen mellom inntak av kaffe og risiko for lungekreft. I forkant av datainnsamling ser vi på sammenhengen som enkel (@fig-kaffe), og den kan forklares med et mystisk molekyl i kaffen som øker risikoen for kreft, og tydeligvis, særlig lungekreft. Vår observasjonstudie bekrefter sammenhengen.


```{r}
#| fig-width: 3
#| fig-height: 1.5
#| fig-align: "center"
#| fig-cap: "Den vitenskapelige modellen for sammenhengen mellom Kaffe (K) et mystisk molekyl (M) og lungekreft (L). Molekylet er ikke observert i vår studie og er derfor markert med en et sirkel."
#| label: fig-kaffe

library(ggdag); library(tidyverse)

coords <-
  tibble(name = c("K", "M", "L"),
         x    = c(1, 2, 3),
         y    = c(1, 1, 1))

# save our DAG
dag1 <-
  dagify(M ~ K,
         L ~ M,
         coords = coords)

dag1 %>%
  tidy_dagitty() %>%
  mutate(circle = if_else(name == "M", "c", "n")) %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = circle)) +
  geom_dag_point(alpha = 1, size = 10, 
         
                 shape = 21) +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  scale_color_manual(values = c("black", "white")) +
  theme_dag() + 
  theme(legend.position = "none") 

```

Men, sier du sikkert, kan ikke det å drikke kaffe være assosiert med andre ting som også øker risikoen for lungekreft? Det kan være at de som drikker mye kaffe også røyker mye, og det er røyking som øker risikoen for lungekreft. En oppdatert modell for sammenhengen mellom kaffe og lungekreft inkluderer røyking som en konfunder (@fig-kaffe-konfunder). I denne modellen ser vi at røyking påvirker både inntak av kaffe og risiko for lungekreft. Når vi kontrollerer for røyking i en statistisk modell så vil vi se at sammenhengen mellom kaffe og lungekreft forsvinner. Det er akkurat hva man gjorde i en meta-analyse som ble publisert i 2016 [@galarraga_coffee_2016]. Når man kontrollerte for røyking så forsvant sammenhengen mellom kaffeinntak og lungekreft. 

```{r}
#| fig-width: 3
#| fig-height: 3
#| fig-align: "center"
#| fig-cap: "En oppdatert vitenskapelige modell for sammenhengen mellom Kaffe (K) og lungekreft (L). Røyking (R) er en konfunder som påvirker både inntak av kaffe og risiko for lungekreft."
#| label: fig-kaffe-konfunder

library(ggdag); library(tidyverse)

coords <-
  tibble(name = c("K", "R", "L"),
         x    = c(1, 2, 3),
         y    = c(1, 2, 1))

# save our DAG
dag2 <-
  dagify(K ~ R,
         L ~ R,
         coords = coords)

dag2 %>%
  tidy_dagitty() %>%
  mutate(obs = "obs") %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = obs)) +
  geom_dag_point(alpha = 1, size = 10, 
         
                 shape = 21) +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  scale_color_manual(values = c("white", "white")) +
  theme_dag() + 
  theme(legend.position = "none") 

```

Det å kontrollere for en potensiell konfunder er en viktig del i en statistisk analyse. I en regresjonsmodell som beskriver en observasjonstudie kan vi kontrollere for en konfunder ved å inkludere den i modellen. I en eksperimentell studie kan vi kontrollere for en konfunder ved å randomisere forsøket.

![I dataene fra vår teoretiske studie er kaffeinntak og røyking assosierte aktiviteter.](img/03-kausal/smoking-coffee.webp){fig-align="center" width="50%" #fig-kaffestudie}

### Rør og mediatoreffekter

Effekten av en spesifikk intervensjon gir ikke alltid en direkte effekt på en avhengig variabel som vi er interesserte av. Isteden kan effekten av intervensjonen påvirke en annen variabel som i sin tur påvirker den avhengige variabelen. Dette kalles for en mediatoreffekt, noe som opptrer i et "rør" i en DAG. I eksemplet med en konfunder såg vi hvordan det å kontrollere for effekten av konfunderen ga oss den sanne kausale effekten mellom to variabler. Når vi har å gjøre med mediatoreffekter kan vi derimot lage trøbbel hvis vi prøver å kontrollere for en slik variabel.

La oss si at $X$ er en intervensjon som vi tror påvirker $Y$ gjennom en tredje variabel $Z$. Vi kan simulere data som gir oss forholdet $X \rightarrow Z \rightarrow Y$ ved å si at $X$ er en normalfordelt variabel med gjennomsnitt 0 og et standardavvik på 1 ($X \sim N(0,1)$). Verdiene på $Z_i$ oppstår gjennom at vi trekker de fra en fordeling med gjennomsnitt $X_i$ og en standardavvik på 1, og på den samme måten oppstår verdiene på $Y_i$ ved at vi trekker de fra en fordeling med gjennomsnitt $Z_i$ og standardavvik 1. I en regresjonsmodell kan vi begynne med og undersøke effekten av av $X$ på $Y$. I denne modellen (Modell 1) ser vi den totale effekten av intervensjonen på $Y$ i tillegg til noe støy. Når vi prøver å legge til $Z$ i en regresjonsmodell forsvinner effekten av $X$ (Modell 2; @fig-ror-posttreatment).

\begin{align}
\text{Modell 1:} \qquad Y &= \beta_0 + \beta_1 X  \\ 
\text{Modell 2:} \qquad  Y &= \beta_0 + \beta_1 X + \beta_2 Z
\end{align}



```{r}
#| label: tbl-ror
#| tbl-cap: "Sammenhengen mellom Y og X estimert ved bruk av lineær regresjon og kontroll av en tredjevariabel som sammenbinder X og Y i et rør."
#| echo: false




library(gt)

set.seed(1)

x <- rnorm(1000, 0, 1)
z <- rnorm(1000, x, 1)

y <- rnorm(1000, z, 1)

m1 <- lm(y ~ x)
m2 <- lm(y ~ x + z)




bind_rows(
  data.frame(coef(summary(m1))) %>%
  select(Estimat = Estimate, Standardfeil = Std..Error) %>%
  rownames_to_column("Koeffisient") %>%
  filter(Koeffisient == "x") %>%
  mutate(Koeffisient = "&#946;<sub>1</sub>", 
         Modell = 1),
  
data.frame(coef(summary(m2))) %>%
  select(Estimat = Estimate, Standardfeil = Std..Error) %>%
  rownames_to_column("Koeffisient") %>%
  filter(Koeffisient %in% c("x", "z")) %>%
  mutate(Koeffisient = if_else(Koeffisient == "x", "&#946;<sub>1</sub>", "&#946;<sub>2</sub>"), 
         Modell = 2)) %>%
  select(Modell, Koeffisient, Estimat, Standardfeil) %>%
  gt() %>%
  fmt_markdown(columns = c(Koeffisient)) %>%
  fmt_number(columns = c(Estimat, Standardfeil), decimals = 2)
  
```


```{r}
#| fig-width: 5
#| fig-height: 5
#| fig-align: "center"
#| fig-cap: "Effekten av intervensjonen (X) påvirker en tredje variabel (Z) som i sin tur påvirker den avhengige variabelen (Y). Ved å kontrollere for Z i en regresjonsmodell forsvinner effekten av X på Y."
#| label: fig-ror-posttreatment

data.frame(x, y, z) %>%
  ggplot(aes(x, y)) + 
  geom_point(shape = 21, fill = "steelblue", alpha = 0.5) + 
  theme_classic() + 
  
  geom_smooth(method = "lm", se = FALSE, color = "steelblue") + 
  
  annotate("segment", 
           x = min(x), xend = max(x),
           y = coef(m2)[1] + coef(m2)[2] * min(x), yend = coef(m2)[1] + coef(m2)[2] * max(x), 
           color = "orchid", 
           linewidth = 1.5) +
  
  annotate("text", x = c(3.2, -2.8), y = c(2.7, 0.4), label = c("Modell 1", "Modell 2"), 
           color = c("steelblue","orchid")) +
  
  
  
  labs(title = "Sammenhengen mellom X og Y")



```


Det å kontrollere for en medierende variabel kalles for post-tretament bias, en metodisk feil som hindrer oss fra å tolke den riktige, kausale effekten av $X$ på $Y$. I eksemplet over ser vi hvordan effekten av intervensjonen forsvinner når vi kontrollerer for den medierende variabelen. Dette er fordi vi har kontrollert for en variabel som er en del av effekten av intervensjonen på den avhengige variabelen, den variabel som vi legger til i regresjonsmodellen spiser opp all effekt. Sagt på en annen måte, vi lærer inget nytt om $X$ på $Y$ når vi kjenner til $Z$, all effekt som $Y$ har fått fra $Z$ kommer fra $X$.

```{r}
#| echo: false

set.seed(666)



N <- 100

## Simulate VO2max and group
VO2 <- rnorm(N, 40, 5)
G <- ifelse(rbinom(N, 1, 0.5) == 1, 2, 1) # 1 = control, 2 = treatment

## Simulate training group effects training compliance

## Simulate a compliance rate between 0 and 1
C <- vector()
for(i in 1:N) {
    C[i] <- ifelse(G[i] == 2, runif(1, 0.4, 0.99),  runif(1, 0.8, 0.99))
}

VO2_post <- vector()
## Simulate VO2max after training
for(i in 1:N) {
  if(G[i] == 2) {
    VO2_post[i] <- VO2[i] * rnorm(1, 1.32, 0.2)
  } else {
    VO2_post[i] <- VO2[i] * rnorm(1, 1.1, 0.2)
  }
}


## Simulate the effect of training compliance on VO2max
VO2_post2 <- VO2 * (VO2_post/VO2 * (C))


mod_dat <- data.frame(id = rep(1:N,2),
           time = factor(rep(c("pre", "post"), each = N), levels = c("pre", "post")),
           G = rep(as.factor(G), 2),
           VO2 = c(VO2,VO2_post2), 
           C = rep(C, 2)) %>%
  pivot_wider(names_from = time, values_from = c(VO2)) 

## Compliance i gruppene

meanG1 <- round(100 * mean(C[G == 1]),0) 
meanG2 <- round(100 * mean(C[G == 2]),0) 


## Total effekt
m1 <- mod_dat %>%
 # filter(C > 0.85) %>%
  
  lm(post ~ pre + G, data = .) 

## Biased effekt
m2 <- mod_dat %>%
  filter(C > 0.85) %>%
  
  lm(post ~ pre + G, data = .) 



```


En post-treatment bias kan også tilsynelatende forsterke effekter. La oss si at vi gjennomfører en intervensjon i en randomisert forsøk. En av to grupper får et nytt treningsprogram og den andre gruppen gjennomfører kontrolltrening. Vi er intressert i å studere effekten av treningsprogrammet på VO<sub>2maks</sub>. Treningsprogrammet er hardt! Noe som leder til at deltakere i studien ikke evner til å gjennomføre alle øktene. I gjennomsnitt gjennomfører kontrollgruppen `r meanG1`% av øktene, men i gjennomsnitt gjennomfører deltakere i intervensjongruppen bare `r meanG2`% av øktene. Når vi gjennomfører analysen ønsker vi å estimere effekten hos de som gjennomført minst 85% av øktene. Vi estimerer effekten av intervensjonen til å gi `r round(coef(m2)[3], 1)` ml<sup>-1<sup> kg<sup>-1</sup> min<sup>-1</sup> høyere VO<sub>2maks</sub> som svar på intervensjonen, sammenlignet med kontrollgruppen. 

```{r}
#| label: fig-posttreatment
#| fig-width: 8
#| fig-height: 4
#| fig-align: "center"
#| fig-cap: "Effekten av intervensjonen (T) påvirker en tredje variabel (gjennomføring, G) som i sin tur påvirker den avhengige variabelen (VO2). Ved å bare analysere de forsøksdeltakere som har gjennomført mer enn 85% av øktene introduserer vi *post-treatment bias*, vi estimerer ikke hele effekten av treningsprogrammet på VO<sub>2maks</sub>."

coords <-
  tibble(name = c("T", "G", "VO2"),
         x    = c(1, 2, 3),
         y    = c(1, 1, 1))

# save our DAG
dag3 <-
  dagify(VO2 ~ G,
         G ~ T,
         coords = coords)

PTDAG <- dag3 %>%
  tidy_dagitty() %>%
  mutate(obs = "obs") %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = obs)) +
  geom_dag_point(alpha = 1, size = 10, 
         
                 shape = 21) +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  scale_color_manual(values = c("white", "white")) +
  theme_dag() + 
  theme(legend.position = "none") 


### Post treatment oppdeling

posttreatmentfig <- data.frame(id = rep(1:N,2),
           time = factor(rep(c("pre", "post"), each = N), levels = c("pre", "post")),
           G = rep(as.factor(G), 2),
           VO2 = c(VO2,VO2_post2), 
           C) %>%
  
  mutate(include = if_else(C > 0.85, "Inkludert\ni analyse", "Ikke inkludert\ni analyse"), 
         G = if_else(G == 2, "Intervensjon", "Kontroll")) %>%
  
  ggplot(aes(time, VO2, group = id, color = G)) + 
  geom_line() + facet_grid(include ~ G) + 
  theme_classic() + 

  labs(title = "VO<sub>2maks</sub> før og etter trening",
       y = "VO<sub>2maks</sub> (ml<sup>-1</sup> kg<sup>-1</sup> min<sup>-1</sup>)", 
       x = "Tid") +
    theme(legend.position = "none", 
        strip.background = element_rect(color = "white", fill = "white"), 
        axis.title.y = element_markdown(), 
        plot.title = element_markdown()) 


library(cowplot)
plot_grid(PTDAG, posttreatmentfig, ncol = 2)



```

Vi har nå et estimat som er for høyt, vi har ikke tatt hensyn til at det er en sammenheng mellom intervensjonen og gjennomføringen av treningsprogrammet. Vi har introdusert en post-treatment bias og vi har ikke beskrevet den totale effekten av intervensjonen på VO<sub>2maks</sub>.

### Collider og seleksjonsbias

En collider er en variabel som påvirkes av to uavhengige variabler. I en DAG kan vi identifisere en collider $Z$ ved at to variabler ($X$ og $Y$) har en felles etterkommer. Når vi analyserer et datasett hvor det finnes en collider risikerer vi å finne en spuriøs sammenheng mellom $X$ og $Y$. Vi simulerer data! $X$ og $Y$ er avhengige hverandre og simuleres som å komme fra en normalfordeling med gjennomsnitt 0 og standardavvik 1 ($X\sim N(0,1),\quad Y\sim N(0,1)$). Collideren påvirkes av begge variablene, vi simulerer den som at vi trekker tall fra en normalfordeling med gjennomsnitt $X_i + Y_i$ og et standardavvik på 1.

Som vi ser i figuren under så er $X$ assosiert med $Z$ og $Y$ er assosiert med $Z$. Når vi ser på sammenhengen mellom $X$ og $Y$ så ser vi at den er ikke-eksisterende. Hva skjer hvis vi analyserer sammenhengen mellom $X$ og $Y$ og kontrollerer for $Z$? 

```{r}
#| label: fig-collider
#| fig-width: 6
#| fig-height: 6
#| fig-align: "center"
#| fig-cap: "Parvise sammenhenger mellom tre variabler. X og Y er uavhengige variabler, Z er en collider som påvirkes av både X og Y."

set.seed(99)
N <- 1000

x <- rnorm(N, 0, 1)
y <- rnorm(N, 0, 1)
z <- rnorm(N, x + y, 1)

df <- data.frame(x, y, z)

p1 <- df %>% ggplot(aes(x, y)) + 
  geom_point(shape = 21, fill = "pink", color = "steelblue", alpha = 0.9) + theme_minimal() + 
  theme(panel.grid = element_blank())

p2 <- df %>% ggplot(aes(x, z)) + 
  geom_point(shape = 21, fill = "pink", color = "steelblue", alpha = 0.9) + theme_minimal() + 
  theme(axis.text.x = element_blank(), axis.title.x = element_blank(), 
        panel.grid = element_blank())

p3 <- df %>% ggplot(aes(y, z)) + 
  geom_point(shape = 21, fill = "pink", color = "steelblue", alpha = 0.9) + theme_minimal()+ 
  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), panel.grid = element_blank())

plot_grid(plot_grid(p2, p1, ncol = 1, align = "vh"), 
          plot_grid(p3, NULL, ncol = 1), ncol = 2, align = "vh")



```

I en enkel regresjonsmodell hvor $Y = \beta_0 + \beta_1 \times X + \beta_2 \times Z$ ser vi at sammenhengen mellom $X$ og $Y$ er tilsynelatende sterk.

```{r}
#| label: tbl-collider
#| tbl-cap: "Sammenhengen mellom Y og X estimert ved bruk av lineær regresjon sammen med en collider (z). "


m <- lm(y ~ x + z, data = df)

coef(summary(m)) %>%
  data.frame() %>%
  select(Estimat = Estimate, Standardfeil = Std..Error) %>%

  rownames_to_column("Koeffisient") %>%
    filter(Koeffisient %in% c("z" ,"x")) %>%
  mutate(Koeffisient = if_else(Koeffisient == "x", "&#946;<sub>1</sub> (x)", "&#946;<sub>2</sub> (z)")) %>%
  gt() %>%
  fmt_markdown(columns = c(Koeffisient)) %>%
  fmt_number(columns = c(Estimat, Standardfeil), decimals = 2)

```

Det å "kontrollere" for en collider introduserer altså sammenhenger som ikke er kausale i en analyse. Vi minner oss igjen på hva en kausal sammenheng er; hvis vi har mulighet å forandre $X$ så vil $Y$ endre seg, hvis det finnes en kausal sammenheng mellom de to. I vårt eksempel så er det ingen kausal sammenheng mellom $X$ og $Y$, sammenhengen som vi måler ved hjelp av regresjonsmodellen er helt spuriøs.

Det finnes situasjoner når data påvirkes av en collider som en konsekvens av hvordan vi samler inn data. I en studie hvor vi ser på sammenhengen mellom VO<sub>2maks</sub> og utnyttelsegrad (laktatterskel som en % av VO<sub>2maks</sub>) i en gruppe av elitesyklister så kan vi se at det er en negativ sammenheng mellom variablene (@fig-elitespur) sammenheng mellom de to variablene. Hvis vi tolker denne sammenhengen som kausal så kan vi kanskje si at syklister som har høyere VO<sub>2maks</sub> forverrer sin laktatterskel. Men det er ikke tilfelle, det er en collider som påvirker begge variablene. Syklister som har høyere VO<sub>2maks</sub> og eller høyere laktatterskel blir selektert til å være med i vårt datasett. Vi har interessert oss for å studerer elitesykklister og har introdusert noe som kalles for seleksjonsbias i vår analyse. 

```{r}
#| label: fig-elitespur
#| fig-width: 5
#| fig-height: 5
#| fig-align: "center"
#| fig-cap: "Sammenhengen mellom VO<sub>2maks</sub> og laktatterskel i en gruppe av elitesyklister. De som har høyere VO<sub>2maks</sub> har lavere laktatterskel."


set.seed(1)
N <- 1000





VO2 <- rnorm(N, 55, 10)
lac <- stats::rbeta(N, 8, 5)



df <- data.frame(VO2, lac) %>%

  mutate(vo2s = VO2/max(VO2),
         lacs = lac/max(lac)) %>%
  rowwise() %>%
  mutate(crit = vo2s + lacs) %>%
  ungroup() %>%
  ## Filter the top 5% of crit variable
  mutate(select = if_else(crit > quantile(crit, 0.95), "select", "notselect")) 

df %>%
  filter(select == "select") %>%
  ggplot(aes(VO2, lac)) + geom_point(shape = 21, fill = "steelblue", 
                                     alpha = 0.6, 
                                     size = 3) +  
  geom_smooth(method = "lm", se = FALSE, color = "steelblue", 
              alpha = 0.4) +
  theme_classic() + 
  labs(title = "Sammenhengen mellom VO<sub>2maks</sub> og laktatterskel i en gruppe av elitesyklister",
       x = "VO<sub>2maks</sub> (ml<sup>-1</sup> kg<sup>-1</sup> min<sup>-1</sup>)",
       y = "Laktatterskel (% av VO<sub>2maks</sub>)") + 
  theme(axis.title.y = element_markdown(), 
        axis.title.x = element_markdown(), 
        plot.title = element_markdown())

 


```

Hvis vi er interessert i den kausale sammenhengen mellom VO<sub>2maks</sub> og laktatterskel så må vi samle inn data på en annen måte. Når vi bare studerer elitesyklister er det det samme som å "kontrollere" for en collider i en regresjonsanalyse, collideren i dette tilfelle er prestasjon. De som presterer best er de som maksimerer summen av underliggende faktorer til prestasjon. Hvis se ser på den totale sammenheng mellom variablene som vi studerte over ser vi ingen sammenheng mellom variablene (@fig-spur-total). Iblant elitesyklister er sammenhengen mellom variablene en spuriøs sammenheng.

```{r}
#| label: fig-spur-total
#| fig-width: 5
#| fig-height: 5
#| fig-align: "center"
#| fig-cap: "Sammenhengen mellom VO<sub>2maks</sub> og laktatterskel i en populasjon sykklister, elitesyklister er de som maksimerer summen av prestasjonsbestemmende variabler."

df %>%

  ggplot(aes(VO2, lac)) + geom_point(shape = 21, 
                                     alpha = 0.6, 
                                     aes(fill = select),
                                     color = "gray30",
                                     size = 3) +  
  geom_smooth(data = filter(df, select == "select"), 
              method = "lm", se = FALSE, 
              alpha = 0.4, color = "steelblue") +
  
    geom_smooth(data = df, 
              method = "lm", se = FALSE, 
              alpha = 0.4, color = "pink") +
  
  theme_classic() + 
  scale_fill_manual(values = c("pink", "steelblue")) +
  scale_color_manual(values = c("pink", "steelblue")) +
  labs(x = "VO<sub>2maks</sub> (ml<sup>-1</sup> kg<sup>-1</sup> min<sup>-1</sup>)",
       y = "Laktatterskel (% av VO<sub>2maks</sub>)") + 
  theme(axis.title.y = element_markdown(), 
        axis.title.x = element_markdown(), 
        plot.title = element_markdown(), 
        legend.position = "none")


```

Dataene over er simulerte men problemet er kjent, og samtidig ikke kjent innad idrettsvitenskapen. Til tross for at mye er skrevet om seleksjonsbias [@borgen_running_2018] fortsetter vi se eksempler på analyser som ikke vurderer seleksjonsbias i toppidrettforskning som en mulig forklaringsmodell.     


### Etterkommer

En etterkommer er en variabel som påvirkes av en eller flere foreldre. Når vi er interessert i å studere kausale effekter så må vi behandle en etterkommer på samme måte som vi behandler en konfunder, collider eller mediatorvariabel. I eksemplene i @fig-dags-des ser vi hvordan en etterkommer kan representere en ikke-observert variabel (Z). D har i disse eksemplene den samme funksjonen som Z. 

```{r}
#| label: fig-dags-des
#| fig-cap: "En etterkommer (D) er en speilbilde av sin forelder og må derfor behandles på samme måte som forelderen når vi er interessert i kausale effekter."
#| fig-width: 5
#| fig-height: 5



library(ggtext)

## FORK
fork_coords <-
  tibble(name = c("X", "Y", "Z", "D"),
         x    = c(1, 3, 2, 2),
         y    = c(1, 1, 2, 1.2))

# save our DAG
fork_dag <-
  dagify(Y ~ Z,
         X ~ Z,
         D ~ Z,
         coords = fork_coords)

## Pipe
pipe_coords <-
  tibble(name = c("X", "Y", "Z", "D"),
         x    = c(1, 3, 2, 1.2),
         y    = c(2, 1, 1.5, 1))

# save our DAG
pipe_dag <-
  dagify(Y ~ Z,
         Z ~ X,
         D ~ Z,
         coords = pipe_coords)


## Collider
collider_coords <-
  tibble(name = c("X", "Y", "Z", "D"),
         x    = c(1, 3, 2, 2),
         y    = c(1, 1, 2, 1.2))

# save our DAG
collider_dag <-
  dagify(Z ~ Y,
         Z ~ X,
         D ~ Z,
         coords = collider_coords)




# plot 
fork <- fork_dag %>%
  tidy_dagitty() %>%
  mutate(circ = if_else(name == "Z", "n", "c")) %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = circ)) +
  geom_dag_point(alpha = 1, size = 12, shape = 21) +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +
  scale_color_manual(values = c("white", "black")) +
  theme(legend.position = "none") + 
  labs(title = "Gaffel")

pipe <- pipe_dag %>%
  tidy_dagitty() %>%
    mutate(circ = if_else(name == "Z", "n", "c")) %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = circ)) +
  geom_dag_point(alpha = 1, size = 12, shape = 21) +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +
  scale_color_manual(values = c("white", "black")) +
  labs(title = "R&#248;r") +
    theme(plot.title = element_markdown(), 
          legend.position = "none") 


collider <- collider_dag %>%
tidy_dagitty() %>%
  mutate(circ = if_else(name == "Z", "n", "c")) %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = circ)) +
  geom_dag_point(alpha = 1, size = 12, shape = 21) +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +
  scale_color_manual(values = c("white", "black")) +

  labs(title = "Collider") +
    theme(plot.title = element_markdown(), 
          legend.position = "none") 




plot_grid(fork, pipe, collider, NULL, ncol = 2)



```





## Kausal analyse, et eksempel

I dataene som vi finner i `fotball_1_2_3.csv` så har vi muligheten å undersøke effektene av spillerprestasjon på årsinntekt. Dataene har blitt presentert i @thrane_performance_2019 hvor man undersøkte hvorvidt effekten av forskjellige uavhengige variabler, som spillerprestasjon og landslagsspill forklarer en spillers markedsverdi og årsinntekt. De norske dataene er unike i den forstand at man faktisk har data på årsinntekt.

Vi skal nå resonnere kring en kausal analyse av dataene. Vi er interesserte i variabelen `årsinntekt` som en avhengig variabel og spillerprestasjon, landslagsspill, nasjonalitet og klubbens prestasjon som uavhengige variabler. Vi starter med en enkel DAG for å illustrerer våre antagelser (@fig-dag-fotball1). I en enkel modell tenker vi oss at spillerprestasjon (P) er variabel som påvirker inntekt. I dataene er inntekt innhentet i 2015, og spillerprestasjon er målt i 2014 [@thrane_performance_2019]. På denne måten kan vi se på variablene som tidsmessig ordnet, noe som understreker antagelsen om den kausale retningen mellom variablene, prestasjon påvirker inntekt. Prestasjonsvariabelen er ikke direkte observert da dataene ikke inneholder en variabel som samlet måler prestasjon, dette markerer vi ved å sette en ring rundt variabelen i figuren.  

```{r} 
#| label: fig-dag-fotball1
#| fig-cap: "Prestasjon påvirker årsinntekt."
#| fig-width: 4
#| fig-height: 2

## FORK
fb1 <-
  tibble(name = c("Inn", "P"),
         x    = c(3, 1),
         y    = c(1.5, 1.5))

# save our DAG
fb1_dag <-
  dagify(Inn ~ P,
         coords = fb1)


fb1_dag %>%
tidy_dagitty() %>%
  mutate(circ = if_else(name == "P", "c", "n")) %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = circ)) +
  geom_dag_point(alpha = 1, size = 12, shape = 21) +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +
  scale_color_manual(values = c("black", "white")) +

    theme(plot.title = element_markdown(), 
          legend.position = "none") 



```

I dataene finner vi flere variabler som er etterkommere av en ikke observert prestasjonvariabel som spilletide, antall mål, antall assist og landslagsspill. Vi kan tenke oss at disse variablene er en speilbilde av prestasjonvariabelen. Vi prøver å sette inn en av to av disse variablene i modellen.

```{r}
#| label: fig-dag-fotball2
#| fig-cap: "Prestasjon påvirker årsinntekt gjennom antall mål (AM) og spilletid (SpT)."
#| fig-width: 4
#| fig-height: 3

## FORK
fb2 <-
  tibble(name = c("Inn", "P", "AM", "SpT"),
         x    = c(3, 1, 2, 2),
         y    = c(1.5, 1.5, 2, 1))

# save our DAG
fb2_dag <-
  dagify(Inn ~ P,
         AM ~ P,
         SpT ~ P, 
         Inn ~ AM, 
         Inn ~ SpT,
         coords = fb2)


fb2_dag %>%
tidy_dagitty() %>%
  mutate(circ = if_else(name == "P", "c", "n")) %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = circ)) +
  geom_dag_point(alpha = 1, size = 12, shape = 21) +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +
  scale_color_manual(values = c("black", "white")) +

    theme(plot.title = element_markdown(), 
          legend.position = "none") 



```

En spillers prestasjon virker gjennom variablene antall mål (AM) og spilletid (SpT) på årsinntekt. Vi kan tenke oss at en spiller som scorer mange mål og spiller mye vil ha en høyere inntekt. Begge variablene er etterkommere av prestasjonvariabelen. Hvis vi kontrollerer for en av disse variablene i en regresjonsmodell så vil vi ikke få en riktig estimat av den *totale* effekten av prestasjon på inntekt. I tillegg vil antall mål ikke være en god indikator for prestasjon i alle spillerposisjoner [@thrane_performance_2019]. 


En mulighet er å bruke spillerbørs som en variabel som samler effekten av prestasjonsvariabler i en variabel. Spillerbørsen er en subjektiv rating av spillernes prestasjon gjennomført an journalister og eksperter [@thrane_performance_2019]. Vi kan tenke oss at spillerbørs er en variabel som er en etterkommer av prestasjonvariabelen og vi kan bruke den som en "proxy" for spillerprestasjon. 


```{r}
#| label: fig-dag-fotball3
#| fig-cap: "Prestasjon påvirker årsinntekt, spillebørs (SB) er en etterkommer av prestasjon."
#| fig-width: 4
#| fig-height: 3

## FORK
fb3 <-
  tibble(name = c("Inn", "P", "SB"),
         x    = c(3, 1, 1.2),
         y    = c(1, 1, 2))

# save our DAG
fb3_dag <-
  dagify(Inn ~ P,
         SB ~ P,
      
       
      
        
         coords = fb3)


fb3_dag %>%
tidy_dagitty() %>%
  mutate(circ = if_else(name == "P", "c", "n")) %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = circ)) +
  geom_dag_point(alpha = 1, size = 12, shape = 21) +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +
  scale_color_manual(values = c("black", "white")) +

    theme(plot.title = element_markdown(), 
          legend.position = "none") 



```

Bedre spillere blir sannsynligvis rekruttert til klubber med evne å betale høyere lønn. Men vi kan tenke oss at rekruttering til klubben skjer på tidligere meritter (historisk prestasjon HP). Hvilken klubb (K) man spiller på kan påvirke prestasjonen, det å spille med bedre medspillere kan bidra til at prestasjonen går opp, og dermed også spillerbørsrating. Klubber har også ulik evne til å betale lønn, dette gjør klubben til en konfunder i analysen. En annen konfunder kan vare alder, eldre spillere har høyere lønn enn yngre spillere, alder og erfarenhet påvirker også prestasjon, til en viss nivå. Når alder blir høyere så vil prestasjonen gå ned. Vår DAG trenger ikke å ta hensyn til en ikke-lineær sammenheng mellom alder og prestasjon, vi kan tenke oss at alder er en konfunder som påvirker prestasjon og inntekt. 

```{r}
#| label: fig-dag-fotball4
#| fig-cap: "Prestasjon påvirker årsinntekt, spillebørs (SB) er en etterkommer av prestasjon og alder (A) og klubb (K) er konfuderer. En spillers klubb påvirkes av historisk prestasjon."
#| fig-width: 5
#| fig-height: 3

## FORK
fb4 <-
  tibble(name = c("Inn", "P", "SB", "A", "HP", "K"),
         x    = c(3, 1, 1.2, 1.8, 1.2, 1.8),
         y    = c(1, 1, 1.7, 1.6, 1.8, 2.2))

# save our DAG
fb4_dag <-
  dagify(Inn ~ P,
         SB ~ P,
         P ~ K, 
         Inn ~ K, 
         P ~ A, 
         Inn ~ A,
         K ~ HP,
        
         coords = fb4)


fb4_dag %>%
tidy_dagitty() %>%
  mutate(circ = if_else(name %in% c("P","HP"), "c", "n")) %>%

  ggplot(aes(x = x, y = y, xend = xend, yend = yend, color = circ)) +
  geom_dag_point(alpha = 1, size = 12, shape = 21) +
  geom_dag_text(color = "black") +
  geom_dag_edges() + 
  theme_dag() + 
    scale_y_continuous(limits = c(0.9, 2.2)) +
  scale_color_manual(values = c("black", "white")) +

    theme(plot.title = element_markdown(), 
          legend.position = "none") 

```

Hvis våre antagelser kan sammenfattes som i @fig-dag-fotball4 så kan vi bruke en regresjonsmodell for å estimere effekten av spillerprestasjon på årsinntekt ved å se på effekten av spillerbørs på inntekt når vi samtidig inkluderer klubb og alder i modellen. Men som vi har sett frem til nå, dette er ikke en lett oppgave, vi har flere effekter som kan påvirke estimatet, noen av dem er ikke observerte. Hvordan vil du for eksempel plassere inn nasjonalitet og landslagsspill i modellen? Spillerbørs er kanskje ikke heller en variabel som utelukkende måler prestasjon, kanskje påvirkes eksperters subjektive rating av historisk prestasjon og forventninger?

Dette eksemplet viser på at en kausal analyse er mulig men krever at vi tenker nøye igjennom hvilke variabler som bør inngå i analysen og hvordan de påvirker modellen, som konfunder, collider eller mediator og etterkommere. Kausale sammenhenger oppdages ikke i dataene alene.



